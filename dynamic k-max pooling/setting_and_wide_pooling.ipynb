{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://arxiv.org/pdf/1404.2188.pdf\n",
    "#A Convolutional Neural Network for Modelling Sentences\n",
    "\n",
    "\n",
    "sentences를 다룰 때, cnn을 사용하면 거리가 먼 words 끼리의 sentences가 pooling 될 일이없음.\n",
    "하지만 k-max pooling을 통해, k개의 active한 값을 뽑아내면서 기존 pooling의 한계 극복\n",
    "\n",
    "i번째 layer의 k = max(ktop, (L-i)*s/L) #L 네트워크 깊이, 문장길이 s, ktop 최상단 층 convolutional layer\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../../downloads/glove.6B\\\\glove.6B.100d.txt',\n",
       " '../../../downloads/glove.6B\\\\glove.6B.200d.txt',\n",
       " '../../../downloads/glove.6B\\\\glove.6B.300d.txt',\n",
       " '../../../downloads/glove.6B\\\\glove.6B.50d.txt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob.glob(\"../../../downloads/glove.6B/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv(\"../../../downloads/toxic/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data['comment_text'] = raw_data['comment_text'].apply(lambda x : x.replace(\"\\n\",\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation Why the edits made under my userna...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\" More I can't make any real suggestions on im...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation Why the edits made under my userna...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \" More I can't make any real suggestions on im...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = raw_data.iloc[:20000,2:]\n",
    "labels['pure'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pure_calcul(x):\n",
    "    if sum(x) == 0:\n",
    "        x['pure'] = 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels.apply(lambda x : pure_calcul(x),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_sum = sum(labels.apply(lambda x : sum(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_weights = (labels.apply(lambda x : sum(x))/labels_sum).apply(lambda x : 1/x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = labels.iloc[:10000,:]\n",
    "test_labels = labels.iloc[10000:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ie-02\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = (to_categorical(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = ' '.join(raw_data.iloc[:10000,:]['comment_text'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = re.compile(r\"[\\(\\[].*?[\\)\\]]\")\n",
    "pp = re.compile(\"[^a-zA-Z ]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = re.sub(p,\"\",texts)\n",
    "texts = re.sub(pp,\"\",texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = texts.replace(\"  \",\" \").replace(\"  \",\" \").replace(\"  \",\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 100\n",
    "max_words = 10000\n",
    "\n",
    "#texts가 존재해야함.\n",
    "\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([texts])\n",
    "tokenizer.num_words = max_words\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(raw_data['comment_text'][:10000].values)\n",
    "\n",
    "\n",
    "data = pad_sequences(sequences, maxlen = maxlen)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "glove_dir = \"../../../downloads/glove.6B/glove.6B.300d.txt\"\n",
    "with open(os.path.join(glove_dir),encoding='utf-8') as fp:\n",
    "    for line in fp:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        params = np.asarray(values[1:],dtype = 'float32')\n",
    "        embeddings_index[word] = params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings_index.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36593"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 300\n",
    "\n",
    "matrix_size = min(len(word_index),max_words)\n",
    "\n",
    "embedding_matrix = np.zeros((len(word_index)+1,embedding_dim))\n",
    "\n",
    "for word, i in word_index.items(): #\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None and i <= matrix_size:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding, Flatten,Dense,Input,Conv1D,Flatten,MaxPooling1D,Concatenate\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = Input(shape = (maxlen,))\n",
    "embedding_layer = Embedding(len(word_index) + 1,embedding_dim,weights =[embedding_matrix],\\\n",
    "                           input_length = maxlen, trainable = False)(input_layer)\n",
    "x1 = Conv1D(128,1, activation = 'relu')(embedding_layer)\n",
    "x2 = Conv1D(128,2, activation = 'relu')(embedding_layer)\n",
    "x3 = Conv1D(128,3, activation = 'relu')(embedding_layer)\n",
    "x4 = Conv1D(128,4, activation = 'relu')(embedding_layer)\n",
    "x5 = Conv1D(128,5, activation = 'relu')(embedding_layer)\n",
    "\n",
    "x1 = MaxPooling1D(2)(x1)\n",
    "x2 = MaxPooling1D(2)(x2)\n",
    "x3 = MaxPooling1D(2)(x3)\n",
    "x4 = MaxPooling1D(2)(x4)\n",
    "x5 = MaxPooling1D(2)(x5)\n",
    "\n",
    "x1 = Conv1D(128,1,activation = 'relu')(x1)\n",
    "x2 = Conv1D(128,2,activation = 'relu')(x2)\n",
    "x3 = Conv1D(128,3,activation = 'relu')(x3)\n",
    "x4 = Conv1D(128,4,activation = 'relu')(x4)\n",
    "x5 = Conv1D(128,5,activation = 'relu')(x5)\n",
    "\n",
    "x1 = MaxPooling1D(2)(x1)\n",
    "x2 = MaxPooling1D(2)(x2)\n",
    "x3 = MaxPooling1D(2)(x3)\n",
    "x4 = MaxPooling1D(2)(x4)\n",
    "x5 = MaxPooling1D(2)(x5)\n",
    "\n",
    "x1 = Conv1D(128,1,activation = 'relu')(x1)\n",
    "x2 = Conv1D(128,2,activation = 'relu')(x2)\n",
    "x3 = Conv1D(128,3,activation = 'relu')(x3)\n",
    "x4 = Conv1D(128,4,activation = 'relu')(x4)\n",
    "x5 = Conv1D(128,5,activation = 'relu')(x5)\n",
    "\n",
    "x1 = Flatten()(x1)\n",
    "x2 = Flatten()(x2)\n",
    "x3 = Flatten()(x3)\n",
    "x4 = Flatten()(x4)\n",
    "x5 = Flatten()(x5)\n",
    "\n",
    "x = Concatenate()([x1,x2,x3,x4,x5])\n",
    "\n",
    "x = Dense(128,activation = 'relu')(x)\n",
    "#x = Dense(len(labels.columns),activation = 'softmax')(x)\n",
    "\n",
    "toxic = Dense(2,activation = 'softmax',name = 'toxic')(x)\n",
    "severe_toxic = Dense(2,activation = 'softmax',name = 'severe_toxic')(x)\n",
    "obscene = Dense(2,activation = 'softmax',name = 'obscene')(x)\n",
    "threat = Dense(2,activation = 'softmax',name = 'threat')(x)\n",
    "insult = Dense(2,activation = 'softmax',name = 'insult')(x)\n",
    "identity_hate = Dense(2,activation = 'softmax',name = 'identity_hate')(x)\n",
    "pure = Dense(2,activation = 'softmax',name = 'pure')(x)\n",
    "\n",
    "model = Model(input_layer, [toxic,severe_toxic,obscene,threat,insult,identity_hate,pure])\n",
    "model.compile(loss = 'binary_crossentropy',loss_weights = labels_weights.to_dict(), optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'toxic': 11.533127889060092,\n",
       " 'severe_toxic': 101.14864864864865,\n",
       " 'obscene': 20.84958217270195,\n",
       " 'threat': 335.14925373134326,\n",
       " 'insult': 21.993143976493634,\n",
       " 'identity_hate': 124.06077348066299,\n",
       " 'pure': 1.2516722408026757}"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat',\n",
       "       'insult', 'identity_hate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 7, 2)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(data,[train_labels[:,0,:],train_labels[:,1,:],train_labels[:,2,:],train_labels[:,3,:],train_labels[:,4,:]\\\n",
    "               ,train_labels[:,5,:],train_labels[:,6,:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "toxic             971\n",
       "severe_toxic      101\n",
       "obscene           527\n",
       "threat             33\n",
       "insult            494\n",
       "identity_hate      84\n",
       "pure             8970\n",
       "dtype: int64"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sequences = tokenizer.texts_to_sequences(raw_data['comment_text'][10000:20000].values)\n",
    "\n",
    "\n",
    "test_data = pad_sequences(test_sequences, maxlen = maxlen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = np.array(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_data = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat',\n",
       "       'insult', 'identity_hate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic = np.argmax(np.array(predict_data)[0],axis=1)\n",
    "toxic = to_categorical(toxic)\n",
    "severe_toxic = np.argmax(np.array(predict_data)[1],axis=1)\n",
    "severe_toxic = to_categorical(severe_toxic)\n",
    "obscene = np.argmax(np.array(predict_data)[2],axis=1)\n",
    "obscene = to_categorical(obscene)\n",
    "threat = np.argmax(np.array(predict_data)[3],axis=1)\n",
    "threat = to_categorical(threat)\n",
    "insult = np.argmax(np.array(predict_data)[4],axis=1)\n",
    "insult = to_categorical(insult)\n",
    "identity_hate = np.argmax(np.array(predict_data)[5],axis=1)\n",
    "identity_hate = to_categorical(identity_hate)\n",
    "pure = np.argmax(np.array(predict_data)[6],axis=1)\n",
    "pure = to_categorical(pure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat',\n",
       "       'insult', 'identity_hate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_categorical(test_labels['toxic'])a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "plus = np.zeros((10000,1))\n",
    "a1=(accuracy_score(toxic,to_categorical(test_labels['toxic'])))\n",
    "a2=(accuracy_score(severe_toxic,to_categorical(test_labels['severe_toxic'])))\n",
    "a3=(accuracy_score(obscene,to_categorical(test_labels['obscene'])))\n",
    "a4=(accuracy_score(np.concatenate([threat,plus],axis=1),to_categorical(test_labels['threat'])))\n",
    "a5=(accuracy_score(insult,to_categorical(test_labels['insult'])))\n",
    "a6=(accuracy_score(np.concatenate([identity_hate,plus],axis=1),to_categorical(test_labels['identity_hate'])))\n",
    "a7=(accuracy_score(pure,to_categorical(test_labels['pure'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9671285714285712"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = np.mean([a1,a2,a3,a4,a5,a6,a7])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#위의 측정방식은 ROC커브를 그려봐야 확실한 측정이 될 수 있다. loss_weights을 조정했음에도 한쪽에 몰빵한 신경망도 나옴\n",
    "#단순히 얼마 대충올랐나 보려고 하는거라 측정방식에 디테일을 쏟지못함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36593"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 100, 300)     10978200    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_91 (Conv1D)              (None, 100, 128)     38528       embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_92 (Conv1D)              (None, 99, 128)      76928       embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_93 (Conv1D)              (None, 98, 128)      115328      embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_94 (Conv1D)              (None, 97, 128)      153728      embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_95 (Conv1D)              (None, 96, 128)      192128      embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_61 (MaxPooling1D) (None, 50, 128)      0           conv1d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_62 (MaxPooling1D) (None, 49, 128)      0           conv1d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_63 (MaxPooling1D) (None, 49, 128)      0           conv1d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_64 (MaxPooling1D) (None, 48, 128)      0           conv1d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_65 (MaxPooling1D) (None, 48, 128)      0           conv1d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_96 (Conv1D)              (None, 50, 128)      16512       max_pooling1d_61[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_97 (Conv1D)              (None, 48, 128)      32896       max_pooling1d_62[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_98 (Conv1D)              (None, 47, 128)      49280       max_pooling1d_63[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_99 (Conv1D)              (None, 45, 128)      65664       max_pooling1d_64[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_100 (Conv1D)             (None, 44, 128)      82048       max_pooling1d_65[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_66 (MaxPooling1D) (None, 25, 128)      0           conv1d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_67 (MaxPooling1D) (None, 24, 128)      0           conv1d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_68 (MaxPooling1D) (None, 23, 128)      0           conv1d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_69 (MaxPooling1D) (None, 22, 128)      0           conv1d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_70 (MaxPooling1D) (None, 22, 128)      0           conv1d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_101 (Conv1D)             (None, 25, 128)      16512       max_pooling1d_66[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_102 (Conv1D)             (None, 23, 128)      32896       max_pooling1d_67[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_103 (Conv1D)             (None, 21, 128)      49280       max_pooling1d_68[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_104 (Conv1D)             (None, 19, 128)      65664       max_pooling1d_69[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_105 (Conv1D)             (None, 18, 128)      82048       max_pooling1d_70[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_31 (Flatten)            (None, 3200)         0           conv1d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_32 (Flatten)            (None, 2944)         0           conv1d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_33 (Flatten)            (None, 2688)         0           conv1d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_34 (Flatten)            (None, 2432)         0           conv1d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_35 (Flatten)            (None, 2304)         0           conv1d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 13568)        0           flatten_31[0][0]                 \n",
      "                                                                 flatten_32[0][0]                 \n",
      "                                                                 flatten_33[0][0]                 \n",
      "                                                                 flatten_34[0][0]                 \n",
      "                                                                 flatten_35[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 128)          1736832     concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "toxic (Dense)                   (None, 2)            258         dense_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "severe_toxic (Dense)            (None, 2)            258         dense_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "obscene (Dense)                 (None, 2)            258         dense_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "threat (Dense)                  (None, 2)            258         dense_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "insult (Dense)                  (None, 2)            258         dense_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "identity_hate (Dense)           (None, 2)            258         dense_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pure (Dense)                    (None, 2)            258         dense_22[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 13,786,278\n",
      "Trainable params: 2,808,078\n",
      "Non-trainable params: 10,978,200\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.engine.topology import Layer\n",
    "from keras import backend as K\n",
    "from keras.utils import conv_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wide pooling은 의미 없는 것 같음.\n",
    "#왜냐면 맨앞 맨뒤의 정보만 개별적으로 하나 넣어주는 효과밖에 안될듯 하지만 구현은 해봄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WidePooling1D(Layer):\n",
    "    def __init__(self,pool_size,padding='valid',**kwargs):\n",
    "        self.pool_size = pool_size\n",
    "        super(WidePooling1D,self).__init__(**kwargs)\n",
    "\n",
    "    def call(self,inputs):\n",
    "        print(K.shape(inputs))\n",
    "        print(K.shape)\n",
    "        empty_place = K.zeros((,self.pool_size,inputs.shape[2]))\n",
    "        #empty_place = K.expand_dims(empty_place,axis=0)\n",
    "        inputs = K.concatenate([empty_place,inputs,empty_place],axis=1)\n",
    "        \n",
    "        return inputs\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0],input_shape[1]+(2*self.pool_size),input_shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"wide_pooling1d_14/Shape:0\", shape=(3,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "input_layer = Input(shape = (maxlen,))\n",
    "embedding_layer = Embedding(len(word_index) + 1,embedding_dim,weights =[embedding_matrix],\\\n",
    "                           input_length = maxlen, trainable = False)(input_layer)\n",
    "x1 = Conv1D(128,1, activation = 'relu')(embedding_layer)\n",
    "x2 = WidePooling1D(pool_size = 3)(x1)\n",
    "x3 = MaxPooling1D(pool_size = 3,strides=1,name='test')(x2)\n",
    "x4 = Conv1D(128,1,activation = 'relu')(x3)\n",
    "x5 = MaxPooling1D(pool_size = 2,strides=1)(x4)\n",
    "x6 = Conv1D(128,1,activation = 'relu')(x5)\n",
    "x7 = Flatten()(x6)\n",
    "x = Dense(128,activation = 'relu')(x7)\n",
    "#x = Dense(len(labels.columns),activation = 'softmax')(x)\n",
    "x = Dense(2,activation = 'softmax')(x)\n",
    "model = Model(input_layer, x)\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.embeddings.Embedding at 0x1f2cb5f2e48>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[1].o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_15 (InputLayer)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "embedding_15 (Embedding)     (None, 100, 300)          10978200  \n",
      "_________________________________________________________________\n",
      "conv1d_27 (Conv1D)           (None, 100, 128)          38528     \n",
      "_________________________________________________________________\n",
      "wide_pooling1d_13 (WidePooli (None, 106, 128)          0         \n",
      "_________________________________________________________________\n",
      "test (MaxPooling1D)          (None, 104, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_28 (Conv1D)           (None, 104, 128)          16512     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 103, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 103, 128)          16512     \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 13184)             0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 128)               1687680   \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 12,737,690\n",
      "Trainable params: 1,759,490\n",
      "Non-trainable params: 10,978,200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      " 9984/10000 [============================>.] - ETA: 0s - loss: 0.2071 - acc: 0.9277"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Incompatible shapes: [64,2] vs. [16,2]\n\t [[{{node training_4/Adam/gradients/loss_6/dense_14_loss/logistic_loss/mul_grad/BroadcastGradientArgs}} = BroadcastGradientArgs[T=DT_INT32, _class=[\"loc:@train...ad/Reshape\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](training_4/Adam/gradients/loss_6/dense_14_loss/logistic_loss/mul_grad/Shape, training_4/Adam/gradients/loss_6/dense_14_loss/logistic_loss/mul_grad/Shape_1)]]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-131-760b3e42b63b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    526\u001b[0m             \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 528\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    529\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m     \u001b[1;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [64,2] vs. [16,2]\n\t [[{{node training_4/Adam/gradients/loss_6/dense_14_loss/logistic_loss/mul_grad/BroadcastGradientArgs}} = BroadcastGradientArgs[T=DT_INT32, _class=[\"loc:@train...ad/Reshape\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](training_4/Adam/gradients/loss_6/dense_14_loss/logistic_loss/mul_grad/Shape, training_4/Adam/gradients/loss_6/dense_14_loss/logistic_loss/mul_grad/Shape_1)]]"
     ]
    }
   ],
   "source": [
    "model.fit(data,[train_labels[:,0,:]],batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "embedding_3 (Embedding)      (None, 100, 300)          10978200  \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 100, 128)          38528     \n",
      "_________________________________________________________________\n",
      "wide_pooling1d_3 (WidePoolin (None, 106, 128)          0         \n",
      "_________________________________________________________________\n",
      "test (MaxPooling1D)          (None, 104, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 104, 128)          16512     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 103, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 103, 128)          16512     \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 13184)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               1687680   \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 12,737,690\n",
      "Trainable params: 1,759,490\n",
      "Non-trainable params: 10,978,200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'max_pooling1d_3/Squeeze:0' shape=(1, 104, 128) dtype=float32>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[4].output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'test/Squeeze:0' shape=(1, 104, 128) dtype=float32>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer(\"test\").output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_test = K.function([input_layer],[model.layers[4].output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,  608,   75,    1,  132,\n",
       "        114,  175,   28,  581, 4060, 1144,   79,  297,   52,   50, 6427,\n",
       "         15,   64, 4364,  143,    7, 3571,   34,  118, 1169, 8834, 2703,\n",
       "          5,   48,  248,    1,  457,   32,    1,   56,   27,  140, 3800,\n",
       "         91])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "want_to_know = l_test([data[:1]])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 104, 128)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "want_to_know.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.62054145, 0.07677186, 0.43080768, 0.42186567, 0.00875566,\n",
       "       0.        , 0.4790943 , 0.09477723, 0.7386753 , 0.68470424,\n",
       "       0.6888691 , 1.0725573 , 0.2181289 , 0.08093468, 0.7286806 ,\n",
       "       0.12981373, 0.        , 0.12720165, 0.2544409 , 0.32327625,\n",
       "       0.        , 1.0854882 , 0.05779046, 0.6074182 , 0.680281  ,\n",
       "       0.12557766, 0.3812653 , 0.00566218, 0.71193725, 0.8322672 ,\n",
       "       0.91000146, 0.12353578, 0.40618366, 0.        , 0.        ,\n",
       "       0.46752194, 0.51196903, 0.        , 0.6799803 , 0.7380056 ,\n",
       "       0.93234026, 0.14133693, 0.22339752, 1.1934353 , 0.5128488 ,\n",
       "       1.05489   , 0.19207083, 0.        , 0.4545156 , 0.79230857,\n",
       "       0.        , 0.8980906 , 0.25274253, 0.10073692, 0.        ,\n",
       "       0.        , 0.40694895, 0.09699701, 0.        , 0.50496227,\n",
       "       0.40818778, 0.        , 0.36311767, 0.7864307 , 0.2881524 ,\n",
       "       0.        , 0.18948539, 0.22644764, 0.        , 0.        ,\n",
       "       0.59630674, 0.4087972 , 0.12323816, 0.3392834 , 0.7990553 ,\n",
       "       0.3486817 , 0.27547637, 0.15810569, 0.26000202, 0.        ,\n",
       "       0.20415682, 0.10935111, 0.        , 0.35995233, 0.87235683,\n",
       "       0.20505354, 0.        , 0.07837709, 0.        , 0.09482189,\n",
       "       0.3840253 , 0.        , 0.397663  , 0.07887329, 0.01627546,\n",
       "       0.11474675, 0.        , 0.2670831 , 0.2914837 , 0.47098368,\n",
       "       0.        , 0.17260456, 0.02880438, 0.        , 0.10570023,\n",
       "       0.22617462, 0.13963816, 0.6947335 , 0.        , 0.        ,\n",
       "       0.11734834, 0.19475088, 0.        , 0.4891412 , 0.59557223,\n",
       "       0.43969575, 0.44677275, 0.0283774 , 0.07660978, 0.41983357,\n",
       "       0.07439374, 0.        , 0.14356442, 0.46272793, 0.7119096 ,\n",
       "       0.        , 0.58361053, 0.4861988 ], dtype=float32)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "want_to_know[0][100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 100, 300)          10978200  \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 100, 128)          38528     \n",
      "_________________________________________________________________\n",
      "wide_pooling1d_1 (WidePoolin (None, 106, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 104, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 104, 128)          16512     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 103, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 103, 128)          16512     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 13184)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               1687680   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 12,737,690\n",
      "Trainable params: 1,759,490\n",
      "Non-trainable params: 10,978,200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KmaxPooling1D(Layer):\n",
    "    def __init__(self,pool_size,padding='valid',**kwargs):\n",
    "        self.pool_size = pool_size\n",
    "        super(KmaxPooling1D,self).__init__(**kwargs)\n",
    "\n",
    "    def call(self,inputs):\n",
    "        inputs = np.sort(inputs,axis=1)\n",
    "        \n",
    "        #empty_place = K.zeros((1,self.pool_size,inputs.shape[2]))\n",
    "        #inputs = K.concatenate([empty_place,inputs,empty_place],axis=1)\n",
    "        \n",
    "        return inputs\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return  #(input_shape[0],input_shape[1]+(2*self.pool_size),input_shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 6],\n",
       "       [0, 4, 7],\n",
       "       [2, 3, 5]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(np.array([[2,1,6],[0,7,4],[5,3,2]]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
