{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ie-02\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input,Dense,LeakyReLU,Conv2D,Conv2DTranspose,Reshape,Flatten, Dropout\n",
    "from keras.models import Model\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generator\n",
    "\n",
    "latent_dim = 32\n",
    "height = 32\n",
    "width = 32\n",
    "channels = 3\n",
    "img_row_shape = 16\n",
    "img_col_shape = 16\n",
    "img_channel_num = 128 # \n",
    "channels = 3\n",
    "generator_input = Input(shape=(latent_dim,))\n",
    "x = Dense(img_channel_num * img_row_shape * img_col_shape)(generator_input)\n",
    "x = LeakyReLU()(x)\n",
    "x = Reshape((img_row_shape,img_col_shape,img_channel_num))(x)\n",
    "\n",
    "x = Conv2D(256,5, padding= 'same')(x)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "x = Conv2DTranspose(256,4, strides = 2, padding='same')(x)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "x = Conv2D(256, 5, padding = 'same')(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Conv2D(256, 5, padding = 'same')(x)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "x = Conv2D(channels, 7 , activation = 'tanh',padding = 'same')(x)\n",
    "generator = Model(generator_input,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32768)             1081344   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 256)       819456    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 32, 32, 256)       1048832   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 256)       1638656   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 256)       1638656   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 32, 32, 3)         37635     \n",
      "=================================================================\n",
      "Total params: 6,264,579\n",
      "Trainable params: 6,264,579\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator_input = Input(shape = (width,height,channels))\n",
    "x = Conv2D(128,3)(discriminator_input)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "x = Conv2D(128,4, strides = 2)(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Conv2D(128,4, strides = 2)(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Conv2D(128,4, strides = 2)(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Flatten()(x)\n",
    "\n",
    "x = Dropout(0.4)(x)\n",
    "x = Dense(1,activation = 'sigmoid')(x)\n",
    "discriminator = Model(discriminator_input,x)\n",
    "discriminator_optimizer = RMSprop(lr = 0.0008,clipvalue = 1.0, decay = 1e-8)\n",
    "discriminator.compile(optimizer = discriminator_optimizer, loss = 'binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.trainable = False\n",
    "gan_input = Input(shape=(latent_dim,))\n",
    "gan_output = discriminator(generator(gan_input)) #ganerator\n",
    "gan = Model(gan_input, gan_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_optimizer = RMSprop(lr=0.0004,clipvalue=1.0,decay=1e-8)\n",
    "gan.compile(optimizer=gan_optimizer, loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing import image\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,y_train),(_,_) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['backend_function.ipynb',\n",
       " 'class activation map.ipynb',\n",
       " 'dcgan.ipynb',\n",
       " 'Grad-CAM.ipynb',\n",
       " 'highway_network.ipynb',\n",
       " 'logs',\n",
       " 'make_layer.ipynb',\n",
       " 'mnist_model1.h5',\n",
       " 'Seperable convolutions.ipynb',\n",
       " 'tensorboard_and_etc.ipynb',\n",
       " 'transpose conv1d.ipynb',\n",
       " 'Variational autoencoder.ipynb',\n",
       " '케라스 창시자에게 배우는 딥러닝']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob.glob(\"*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train[y_train.flatten()==6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=32x32 at 0x1501AEF8C18>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#image.array_to_img(x_train[16] * 255., scale=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape((x_train.shape[0],) + \\\n",
    "                         (width,height,channels)).astype('float32')/255.\n",
    "iterations = 10000\n",
    "batch_size = 20\n",
    "save_dir = \"./frog/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ie-02\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step :  0\n",
      "d_loss 0.6939697\n",
      "a_loss 0.30729717\n",
      "step :  1\n",
      "d_loss 8.483915\n",
      "a_loss 1.0000001e-07\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-fe190c0c02fb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mmisleading_targets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0ma_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_latent_vectors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmisleading_targets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"step : \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1217\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1218\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start = 0 \n",
    "for step in range(iterations):\n",
    "    random_latent_vectors = np.random.normal(size=(batch_size,latent_dim))\n",
    "    generated_images = generator.predict(random_latent_vectors)\n",
    "    stop = start + batch_size\n",
    "    real_images = x_train[start : stop]\n",
    "    combined_images = np.concatenate([generated_images, real_images])\n",
    "    labels = np.concatenate([np.ones((batch_size,1)),\\\n",
    "                            np.zeros((batch_size,1))])\n",
    "    labels += 0.05 * np.random.random(labels.shape)\n",
    "    d_loss = discriminator.train_on_batch(combined_images, labels)\n",
    "    \n",
    "    random_latent_vectors = np.random.normal(size = (batch_size, latent_dim))\n",
    "    \n",
    "    misleading_targets = np.zeros((batch_size,1))\n",
    "    \n",
    "    a_loss = gan.train_on_batch(random_latent_vectors, misleading_targets)\n",
    "    \n",
    "    print(\"step : \", step)\n",
    "    print(\"d_loss\",d_loss)\n",
    "    print(\"a_loss\",a_loss)\n",
    "    start += batch_size \n",
    "    if start > len(x_train) - batch_size : \n",
    "        start =0\n",
    "    if step % 10 == 0 :\n",
    "        gan.save_weights(\"gan.h5\")\n",
    "        img = image.array_to_img(generated_images[0] * 255., scale=False)\n",
    "        img.save(os.path.join(save_dir,'generated_frog'+str(step)+\".png\"))\n",
    "        \n",
    "        img = image.array_to_img(real_images[0]*255.,scale=False)\n",
    "        img.save(os.path.join(save_dir,'real_frog'+str(step)+\".png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_latent_vectors = np.random.normal(size=(batch_size,latent_dim))\n",
    "generated_images = generator.predict(random_latent_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[125.75818 , 122.77238 ,  83.88971 ],\n",
       "        [160.7787  , 150.93257 , 122.54014 ],\n",
       "        [185.96129 , 182.63463 , 147.74286 ],\n",
       "        ...,\n",
       "        [156.7285  , 172.31265 , 146.18967 ],\n",
       "        [126.305984, 142.55853 , 121.66157 ],\n",
       "        [ 98.31809 , 116.23361 ,  89.71459 ]],\n",
       "\n",
       "       [[155.14279 , 156.26834 , 108.88179 ],\n",
       "        [189.66655 , 183.28598 , 153.17587 ],\n",
       "        [213.934   , 214.83406 , 182.15257 ],\n",
       "        ...,\n",
       "        [191.2919  , 204.90579 , 181.18228 ],\n",
       "        [162.01343 , 178.17487 , 154.10649 ],\n",
       "        [129.63663 , 148.35538 , 115.977715]],\n",
       "\n",
       "       [[177.3209  , 180.88737 , 138.11836 ],\n",
       "        [210.74405 , 210.34508 , 185.71481 ],\n",
       "        [230.57455 , 232.84407 , 211.94171 ],\n",
       "        ...,\n",
       "        [215.74982 , 226.28506 , 214.59598 ],\n",
       "        [189.41112 , 202.15685 , 189.03174 ],\n",
       "        [158.27895 , 173.5449  , 149.50385 ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[176.27022 , 180.20851 , 137.39114 ],\n",
       "        [208.66568 , 211.01505 , 183.87907 ],\n",
       "        [230.19295 , 234.42207 , 212.71294 ],\n",
       "        ...,\n",
       "        [224.02872 , 231.88309 , 224.79262 ],\n",
       "        [199.28088 , 212.14325 , 203.36053 ],\n",
       "        [163.58307 , 177.67638 , 164.40324 ]],\n",
       "\n",
       "       [[146.3032  , 148.6941  , 114.35364 ],\n",
       "        [178.16267 , 184.37492 , 154.2868  ],\n",
       "        [206.60753 , 212.74905 , 188.73793 ],\n",
       "        ...,\n",
       "        [197.51915 , 208.62564 , 207.84424 ],\n",
       "        [166.57603 , 183.12495 , 180.53925 ],\n",
       "        [129.24696 , 143.19827 , 146.11884 ]],\n",
       "\n",
       "       [[116.472336, 108.98024 ,  88.344925],\n",
       "        [146.55008 , 141.24579 , 123.623405],\n",
       "        [174.28456 , 175.17049 , 154.94855 ],\n",
       "        ...,\n",
       "        [161.81125 , 174.31967 , 175.00171 ],\n",
       "        [130.60638 , 146.27258 , 147.62958 ],\n",
       "        [ 96.302055, 110.47005 , 112.76933 ]]], dtype=float32)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_images[0]*255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAADUElEQVR4nK1W21IbRxTsPjN7QxY4YJtAmSr7wZ+Tn0lVvjapFJiAgcQJxUVIq5npPMxqLYFkjOCsandqL93n9PRoDn/79ZeP+5/2Puzu7O41G4OqHphzdI4ASEj5TBrQnUFCIInZOwIkxZgmob0bjy+vb05Ozw+Pv5yeHvr3H3YP9g/2Ph683n7XNJveF+YK0ggKIimpwwIAEBTAnjuHJCClFFKYtJOfXo+qZlBUtS+n/u3ewe77jztv94fDN0Wx4VxhtD49LI2uJs7KAwBBkpJSXYWqmoiDFJvQBv/zu53t7Z3N4XZTbzpXkp4kQCxhWMGHjiAf3kXnyii2Id6OL/2g2aqbV0XROFeadeIsYBHQ98EBZEFBCEaIdVEP6sFwsOXrpirLyrvC6EgjLYMtAD6GLsxqFkgzg/e+KKuyqr230syTDrPcv6f+qvR7lUgKJI3OmytcYc7DjCQJPjK3j9PMmY2gmTkzwnWyrAm7kswAwowGQC8K3luQIgwpe4bfnj4fP4dgosEE5N/s9nNjhkAkypQWXX9/zKc7aq4C0MgEaBnIKtYfp2KCTHmCHxdmjTrkYAamtVNciUyIICkqu+hhBWuvNWS0PHVGm7mI9xie56XMQ2NeB8olLUtlbQaChLoKuCTfH7mzGh4AQRpIg/hQoAeIT1asmwPQg7mC+ZXMufGaIUD5v0iJ0pOX66NBkFJezAlIedN+QYIMJ8hSVFJuO9BfXgBdkFKK8lFTpSAldVbtepG5txeC967LoCFIKUohBd9OQoghpSglIRF5A1r8vlePvd+0SEKhL16SUlIMIbRTfze5bSfjkFqfIpwxt3Gr5kM9LrGwEeamCICSFBVDmo7bdjQe+evLm5utq3qw6az2wIzhngI9H7sjj9VRffO4FJVCCONJezO6vbq89SfnZ1Xzxqoywapqw7nSaIDNPtM8AcFMP9f9kb0wuT2NcdJO/ru6+ufr32cXJ/7z0YW54+jKcctBM/RF482B1ueU1KVKgnQkSDMStIxPSSCgmBRjHLfh9u7u7OLy8OTLn3/8609+P+ekmY5ws9cOX20WVVN4LzqDEkilJBEQ6AiYc0aaMwJ0xq6jTwBSmkaFaRhN2qvr0enF16O/jo8+H/4PhkCwQRD6hlIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=32x32 at 0x255989A02B0>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.array_to_img(generated_images[7] * 255., scale=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
