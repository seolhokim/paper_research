{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input,Dense,LeakyReLU,Conv2D,Conv2DTranspose,Reshape,Flatten, Dropout,BatchNormalization,Activation\n",
    "from keras.models import Model\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generator\n",
    "\n",
    "latent_dim = 32\n",
    "height = 32\n",
    "width = 32\n",
    "channels = 3\n",
    "img_row_shape = 16\n",
    "img_col_shape = 16\n",
    "img_channel_num = 128 # \n",
    "channels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_input = Input(shape=(latent_dim,))\n",
    "x = Dense(img_channel_num * img_row_shape * img_col_shape)(generator_input)\n",
    "x = LeakyReLU()(x)\n",
    "#x = BatchNormalization()(x)\n",
    "#x = Activation('tanh')(x)\n",
    "x = Reshape((img_row_shape,img_col_shape,img_channel_num))(x)\n",
    "\n",
    "x = Conv2D(256,5, padding= 'same')(x)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "x = Conv2DTranspose(256,4, strides = 2, padding='same')(x)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "x = Conv2D(256, 5, padding = 'same')(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Conv2D(256, 5, padding = 'same')(x)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "x = Conv2D(channels, 7 , activation = 'tanh',padding = 'same')(x)\n",
    "generator = Model(generator_input,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_13 (InputLayer)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 32768)             1081344   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_35 (LeakyReLU)   (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "reshape_5 (Reshape)          (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 16, 16, 256)       819456    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_36 (LeakyReLU)   (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTr (None, 32, 32, 256)       1048832   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_37 (LeakyReLU)   (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 32, 32, 256)       1638656   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_38 (LeakyReLU)   (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 32, 32, 256)       1638656   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_39 (LeakyReLU)   (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 32, 32, 3)         37635     \n",
      "=================================================================\n",
      "Total params: 6,264,579\n",
      "Trainable params: 6,264,579\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator_input = Input(shape = (width,height,channels))\n",
    "x = Conv2D(128,3)(discriminator_input)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "x = Conv2D(128,4, strides = 2)(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Conv2D(128,4, strides = 2)(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Conv2D(128,4, strides = 2)(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Flatten()(x)\n",
    "\n",
    "x = Dropout(0.4)(x)\n",
    "x = Dense(1,activation = 'sigmoid')(x)\n",
    "discriminator = Model(discriminator_input,x)\n",
    "discriminator_optimizer = RMSprop(lr = 0.0002,clipvalue = 1.0, decay = 1e-8)\n",
    "discriminator.compile(optimizer = discriminator_optimizer, loss = 'binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.trainable = False\n",
    "gan_input = Input(shape=(latent_dim,))\n",
    "gan_output = discriminator(generator(gan_input)) #ganerator\n",
    "gan = Model(gan_input, gan_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_optimizer = RMSprop(lr=0.0002,clipvalue=1.0,decay=1e-8)\n",
    "gan.compile(optimizer=gan_optimizer, loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing import image\n",
    "import os\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,y_train),(_,_) = cifar10.load_data()\n",
    "x_train = x_train[y_train.flatten()==6]\n",
    "x_train = x_train.reshape((x_train.shape[0],) + \\\n",
    "                         (width,height,channels)).astype('float32')/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "iterations = 10000\n",
    "batch_size = 20\n",
    "save_dir = \"./frog/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ie-02\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step :  0\n",
      "d_loss 0.69263273\n",
      "a_loss 0.6890968\n",
      "step :  1\n",
      "d_loss 0.7562637\n",
      "a_loss 0.6550635\n",
      "step :  2\n",
      "d_loss 0.7404889\n",
      "a_loss 1.5795376\n",
      "step :  3\n",
      "d_loss 0.6163844\n",
      "a_loss 1.4539428\n",
      "step :  4\n",
      "d_loss 0.58673203\n",
      "a_loss 1.9255108\n",
      "step :  5\n",
      "d_loss 0.9118416\n",
      "a_loss 0.72408056\n",
      "step :  6\n",
      "d_loss 0.68790114\n",
      "a_loss 0.6672213\n",
      "step :  7\n",
      "d_loss 0.82242477\n",
      "a_loss 0.8968428\n",
      "step :  8\n",
      "d_loss 0.6997913\n",
      "a_loss 0.64795905\n",
      "step :  9\n",
      "d_loss 0.74073035\n",
      "a_loss 0.9175046\n",
      "step :  10\n",
      "d_loss 0.73884666\n",
      "a_loss 0.6772267\n",
      "step :  11\n",
      "d_loss 0.64379376\n",
      "a_loss 0.6267418\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-fe190c0c02fb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mmisleading_targets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0ma_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_latent_vectors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmisleading_targets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"step : \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1217\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1218\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start = 0 \n",
    "for step in range(iterations):\n",
    "    random_latent_vectors = np.random.normal(size=(batch_size,latent_dim))\n",
    "    generated_images = generator.predict(random_latent_vectors)\n",
    "    stop = start + batch_size\n",
    "    real_images = x_train[start : stop]\n",
    "    combined_images = np.concatenate([generated_images, real_images])\n",
    "    labels = np.concatenate([np.ones((batch_size,1)),\\\n",
    "                            np.zeros((batch_size,1))])\n",
    "    labels += 0.05 * np.random.random(labels.shape)\n",
    "    d_loss = discriminator.train_on_batch(combined_images, labels)\n",
    "    \n",
    "    random_latent_vectors = np.random.normal(size = (batch_size, latent_dim))\n",
    "    \n",
    "    misleading_targets = np.zeros((batch_size,1))\n",
    "    \n",
    "    a_loss = gan.train_on_batch(random_latent_vectors, misleading_targets)\n",
    "    \n",
    "    print(\"step : \", step)\n",
    "    print(\"d_loss\",d_loss)\n",
    "    print(\"a_loss\",a_loss)\n",
    "    start += batch_size \n",
    "    if start > len(x_train) - batch_size : \n",
    "        start =0\n",
    "    if step % 10 == 0 :\n",
    "        gan.save_weights(\"gan.h5\")\n",
    "        img = image.array_to_img(generated_images[0] * 255., scale=False)\n",
    "        img.save(os.path.join(save_dir,'generated_frog'+str(step)+\".png\"))\n",
    "        \n",
    "        img = image.array_to_img(real_images[0]*255.,scale=False)\n",
    "        img.save(os.path.join(save_dir,'real_frog'+str(step)+\".png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSGAN():\n",
    "    def __init__(self):\n",
    "        self.latent_dim = 32\n",
    "        self.img_channel_num = 128 #generator 에서 생성될 channel num\n",
    "        self.img_row_shape = 16 #generator 에서 생성될 row\n",
    "        self.img_col_shape = 16 #generator 에서 생성될 col\n",
    "        self.output_channels = 3 #generator 에서 나올 channels 당연히 3\n",
    "        \n",
    "        self.row = 32 #discriminator에 들어갈 row shape = generator의 output\n",
    "        self.col = 32 #discriminator에 들어갈 col shape\n",
    "        self.generator = self.build_generator()\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator_optimizer = Adam(lr=0.0002)\n",
    "        self.gan_optimizer = Adam(lr =0.0002)\n",
    "        self.discriminator.compile(loss = 'mse', optimizer = self.discriminator_optimizer,\\\n",
    "                                  metrics = ['accuracy'])\n",
    "        \n",
    "        self.discriminator.trainable = False\n",
    "        \n",
    "        gan_input = Input(shape=(self.latent_dim,))\n",
    "        gan_output = self.discriminator(self.generator(gan_input))\n",
    "        self.gan = Model(gan_input,gan_output)\n",
    "        self.gan.compile(loss = 'mse',optimizer = self.gan_optimizer)\n",
    "        \n",
    "    def build_generator(self):\n",
    "        generator_input = Input(shape=(self.latent_dim,))\n",
    "        x = Dense(self.img_channel_num * self.img_row_shape * self.img_col_shape)(generator_input)\n",
    "        x = LeakyReLU()(x)            \n",
    "        x = Reshape((self.img_row_shape,self.img_col_shape,self.img_channel_num))(x)\n",
    "\n",
    "        x = Conv2D(256,5, padding= 'same')(x)\n",
    "        x = LeakyReLU()(x)\n",
    "\n",
    "        x = Conv2DTranspose(256,4, strides = 2, padding='same')(x)\n",
    "        x = LeakyReLU()(x)\n",
    "\n",
    "        x = Conv2D(256, 5, padding = 'same')(x)\n",
    "        x = LeakyReLU()(x)\n",
    "        x = Conv2D(256, 5, padding = 'same')(x)\n",
    "        x = LeakyReLU()(x)\n",
    "        x = Conv2D(self.output_channels, 7 , activation = 'tanh',padding = 'same')(x)\n",
    "        generator = Model(generator_input,x)\n",
    "        return generator\n",
    "    \n",
    "    def build_discriminator(self):\n",
    "        discriminator_input = Input(shape = (self.row,self.col,self.output_channels))\n",
    "        x = Conv2D(128,3)(discriminator_input)\n",
    "        x = LeakyReLU()(x)\n",
    "\n",
    "        x = Conv2D(128,4, strides = 2)(x)\n",
    "        x = LeakyReLU()(x)\n",
    "        x = Conv2D(128,4, strides = 2)(x)\n",
    "        x = LeakyReLU()(x)\n",
    "        x = Conv2D(128,4, strides = 2)(x)\n",
    "        x = LeakyReLU()(x)\n",
    "        x = Flatten()(x)\n",
    "\n",
    "        x = Dropout(0.4)(x)\n",
    "        x = Dense(1,activation = 'sigmoid')(x)\n",
    "        discriminator = Model(discriminator_input,x)\n",
    "        return discriminator\n",
    "        \n",
    "    def train(self, X_train,epochs, batch_size=128, sample_interval=50,save_dir = \"./lsgan_frog/\"):\n",
    "\n",
    "        # Rescale -1 to 1\n",
    "        X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = np.ones((batch_size, 1))\n",
    "        valid += 0.05 * np.random.random(valid.shape)\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "        fake += 0.05 * np.random.random(fake.shape)\n",
    "        start = 0\n",
    "        for step in range(iterations):\n",
    "            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "            gen_images = self.generator.predict(noise)\n",
    "            stop = start + batch_size\n",
    "            real_images = X_train[start : stop]\n",
    "            #combined_images = np.concatenate([generated_images, real_images])\n",
    "            #combined_labels = np.concatenate([fake,valid])\n",
    "            #combined_labels += 0.05 * np.random.random(combined_labels.shape)\n",
    "            \n",
    "            d_loss_real = self.discriminator.train_on_batch(real_images, valid)\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_images, fake)\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "            \n",
    "            g_loss = self.gan.train_on_batch(noise, valid)\n",
    "            \n",
    "            print(\"step : \", step)\n",
    "            print(\"d_loss\",d_loss)\n",
    "            print(\"d_loss_real\",d_loss_real)\n",
    "            print(\"d_loss_fake\",d_loss_fake)\n",
    "            print(\"g_loss\",g_loss)\n",
    "            start += batch_size \n",
    "            if start > len(x_train) - batch_size : \n",
    "                start =0\n",
    "            if step % 10 == 0 :\n",
    "                gan.save_weights(\"lsgan.h5\")\n",
    "                img = image.array_to_img((generated_images[0] * 127.5)+127.5, scale=False)\n",
    "                img.save(os.path.join(save_dir,'generated_frog_'+str(step)+\".png\"))\n",
    "\n",
    "                img = image.array_to_img((real_images[0] * 127.5) + 127.5,scale=False)\n",
    "                img.save(os.path.join(save_dir,'real_frog_'+str(step)+\".png\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=32x32 at 0x22C3B2CE6A0>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.array_to_img(x_train[5]*255,scale=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSGAN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,y_train),(_,_) = cifar10.load_data()\n",
    "x_train = x_train[y_train.flatten()==6]\n",
    "x_train = x_train.reshape((x_train.shape[0],) + \\\n",
    "                         (width,height,channels)).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ie-02\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step :  0\n",
      "d_loss [0.24976125 0.        ]\n",
      "d_loss_real [0.27296102, 0.0]\n",
      "d_loss_fake [0.2265615, 0.0]\n",
      "g_loss 0.27339375\n",
      "step :  1\n",
      "d_loss [0.2063446 0.       ]\n",
      "d_loss_real [0.17054757, 0.0]\n",
      "d_loss_fake [0.24214165, 0.0]\n",
      "g_loss 0.25287193\n",
      "step :  2\n",
      "d_loss [0.21727777 0.        ]\n",
      "d_loss_real [0.09385974, 0.0]\n",
      "d_loss_fake [0.3406958, 0.0]\n",
      "g_loss 0.17471339\n",
      "step :  3\n",
      "d_loss [0.3230943 0.       ]\n",
      "d_loss_real [0.052498315, 0.0]\n",
      "d_loss_fake [0.5936903, 0.0]\n",
      "g_loss 0.07352994\n",
      "step :  4\n",
      "d_loss [0.390272 0.      ]\n",
      "d_loss_real [0.03942565, 0.0]\n",
      "d_loss_fake [0.7411183, 0.0]\n",
      "g_loss 0.0475699\n",
      "step :  5\n",
      "d_loss [0.3803041 0.       ]\n",
      "d_loss_real [0.04680335, 0.0]\n",
      "d_loss_fake [0.71380484, 0.0]\n",
      "g_loss 0.07615239\n",
      "step :  6\n",
      "d_loss [0.29621056 0.        ]\n",
      "d_loss_real [0.06622911, 0.0]\n",
      "d_loss_fake [0.526192, 0.0]\n",
      "g_loss 0.22623888\n",
      "step :  7\n",
      "d_loss [0.13002266 0.        ]\n",
      "d_loss_real [0.10994684, 0.0]\n",
      "d_loss_fake [0.15009847, 0.0]\n",
      "g_loss 0.58909345\n",
      "step :  8\n",
      "d_loss [0.0966242 0.       ]\n",
      "d_loss_real [0.16927621, 0.0]\n",
      "d_loss_fake [0.023972195, 0.0]\n",
      "g_loss 0.8316996\n",
      "step :  9\n",
      "d_loss [0.07915783 0.        ]\n",
      "d_loss_real [0.15493378, 0.0]\n",
      "d_loss_fake [0.0033818856, 0.0]\n",
      "g_loss 0.9323217\n",
      "step :  10\n",
      "d_loss [0.10051749 0.        ]\n",
      "d_loss_real [0.200234, 0.0]\n",
      "d_loss_fake [0.0008009808, 0.0]\n",
      "g_loss 0.9717451\n",
      "step :  11\n",
      "d_loss [0.09607375 0.        ]\n",
      "d_loss_real [0.1916278, 0.0]\n",
      "d_loss_fake [0.0005197085, 0.0]\n",
      "g_loss 0.9747993\n",
      "step :  12\n",
      "d_loss [0.07003637 0.        ]\n",
      "d_loss_real [0.13955405, 0.0]\n",
      "d_loss_fake [0.000518678, 0.0]\n",
      "g_loss 0.9650001\n",
      "step :  13\n",
      "d_loss [0.06453838 0.        ]\n",
      "d_loss_real [0.12801795, 0.0]\n",
      "d_loss_fake [0.0010588116, 0.0]\n",
      "g_loss 0.92966396\n",
      "step :  14\n",
      "d_loss [0.0615309 0.       ]\n",
      "d_loss_real [0.119967006, 0.0]\n",
      "d_loss_fake [0.0030948024, 0.0]\n",
      "g_loss 0.870945\n",
      "step :  15\n",
      "d_loss [0.04270372 0.        ]\n",
      "d_loss_real [0.07669229, 0.0]\n",
      "d_loss_fake [0.008715143, 0.0]\n",
      "g_loss 0.80546296\n",
      "step :  16\n",
      "d_loss [0.05671353 0.        ]\n",
      "d_loss_real [0.09538263, 0.0]\n",
      "d_loss_fake [0.018044418, 0.0]\n",
      "g_loss 0.76706755\n",
      "step :  17\n",
      "d_loss [0.04728122 0.        ]\n",
      "d_loss_real [0.07512248, 0.0]\n",
      "d_loss_fake [0.019439958, 0.0]\n",
      "g_loss 0.78763664\n",
      "step :  18\n",
      "d_loss [0.04108019 0.        ]\n",
      "d_loss_real [0.07029262, 0.0]\n",
      "d_loss_fake [0.0118677635, 0.0]\n",
      "g_loss 0.8291484\n",
      "step :  19\n",
      "d_loss [0.02711176 0.        ]\n",
      "d_loss_real [0.047374196, 0.0]\n",
      "d_loss_fake [0.0068493336, 0.0]\n",
      "g_loss 0.87593895\n",
      "step :  20\n",
      "d_loss [0.02827093 0.        ]\n",
      "d_loss_real [0.05308031, 0.0]\n",
      "d_loss_fake [0.00346156, 0.0]\n",
      "g_loss 0.9023765\n",
      "step :  21\n",
      "d_loss [0.02643285 0.        ]\n",
      "d_loss_real [0.049988322, 0.0]\n",
      "d_loss_fake [0.0028773719, 0.0]\n",
      "g_loss 0.91429174\n",
      "step :  22\n",
      "d_loss [0.02322733 0.        ]\n",
      "d_loss_real [0.04383049, 0.0]\n",
      "d_loss_fake [0.0026241746, 0.0]\n",
      "g_loss 0.90134925\n",
      "step :  23\n",
      "d_loss [0.01640025 0.        ]\n",
      "d_loss_real [0.029517986, 0.0]\n",
      "d_loss_fake [0.0032825104, 0.0]\n",
      "g_loss 0.8855024\n",
      "step :  24\n",
      "d_loss [0.01779684 0.        ]\n",
      "d_loss_real [0.030208722, 0.0]\n",
      "d_loss_fake [0.005384955, 0.0]\n",
      "g_loss 0.8574518\n",
      "step :  25\n",
      "d_loss [0.01686133 0.        ]\n",
      "d_loss_real [0.027239371, 0.0]\n",
      "d_loss_fake [0.0064832843, 0.0]\n",
      "g_loss 0.86720705\n",
      "step :  26\n",
      "d_loss [0.01150117 0.        ]\n",
      "d_loss_real [0.017672807, 0.0]\n",
      "d_loss_fake [0.0053295232, 0.0]\n",
      "g_loss 0.88465834\n",
      "step :  27\n",
      "d_loss [0.01756471 0.        ]\n",
      "d_loss_real [0.030361202, 0.0]\n",
      "d_loss_fake [0.0047682095, 0.0]\n",
      "g_loss 0.8939506\n",
      "step :  28\n",
      "d_loss [0.00632186 0.        ]\n",
      "d_loss_real [0.00919405, 0.0]\n",
      "d_loss_fake [0.0034496626, 0.0]\n",
      "g_loss 0.91971207\n",
      "step :  29\n",
      "d_loss [0.01070536 0.        ]\n",
      "d_loss_real [0.01936072, 0.0]\n",
      "d_loss_fake [0.0020499998, 0.0]\n",
      "g_loss 0.93601424\n",
      "step :  30\n",
      "d_loss [0.00513617 0.        ]\n",
      "d_loss_real [0.008781191, 0.0]\n",
      "d_loss_fake [0.0014911556, 0.0]\n",
      "g_loss 0.94031596\n",
      "step :  31\n",
      "d_loss [0.00357692 0.        ]\n",
      "d_loss_real [0.0061959834, 0.0]\n",
      "d_loss_fake [0.0009578577, 0.0]\n",
      "g_loss 0.9552279\n",
      "step :  32\n",
      "d_loss [0.00694133 0.        ]\n",
      "d_loss_real [0.012843906, 0.0]\n",
      "d_loss_fake [0.0010387468, 0.0]\n",
      "g_loss 0.941441\n",
      "step :  33\n",
      "d_loss [0.0059437 0.       ]\n",
      "d_loss_real [0.009785653, 0.0]\n",
      "d_loss_fake [0.0021017415, 0.0]\n",
      "g_loss 0.91636\n",
      "step :  34\n",
      "d_loss [0.00642976 0.        ]\n",
      "d_loss_real [0.009807522, 0.0]\n",
      "d_loss_fake [0.0030519895, 0.0]\n",
      "g_loss 0.9024119\n",
      "step :  35\n",
      "d_loss [0.00324661 0.        ]\n",
      "d_loss_real [0.003926524, 0.0]\n",
      "d_loss_fake [0.002566706, 0.0]\n",
      "g_loss 0.94306695\n",
      "step :  36\n",
      "d_loss [0.00170227 0.        ]\n",
      "d_loss_real [0.002240441, 0.0]\n",
      "d_loss_fake [0.0011640915, 0.0]\n",
      "g_loss 0.9792238\n",
      "step :  37\n",
      "d_loss [0.00641038 0.        ]\n",
      "d_loss_real [0.012414925, 0.0]\n",
      "d_loss_fake [0.00040584157, 0.0]\n",
      "g_loss 0.97711205\n",
      "step :  38\n",
      "d_loss [0.00336716 0.        ]\n",
      "d_loss_real [0.006273357, 0.0]\n",
      "d_loss_fake [0.00046095642, 0.0]\n",
      "g_loss 0.97783434\n",
      "step :  39\n",
      "d_loss [0.00616127 0.        ]\n",
      "d_loss_real [0.011478174, 0.0]\n",
      "d_loss_fake [0.0008443572, 0.0]\n",
      "g_loss 0.95254445\n",
      "step :  40\n",
      "d_loss [0.00256335 0.        ]\n",
      "d_loss_real [0.0034902017, 0.0]\n",
      "d_loss_fake [0.0016365007, 0.0]\n",
      "g_loss 0.9536597\n",
      "step :  41\n",
      "d_loss [0.00479613 0.        ]\n",
      "d_loss_real [0.008566716, 0.0]\n",
      "d_loss_fake [0.0010255477, 0.0]\n",
      "g_loss 0.9706697\n",
      "step :  42\n",
      "d_loss [0.00491901 0.        ]\n",
      "d_loss_real [0.008897038, 0.0]\n",
      "d_loss_fake [0.0009409917, 0.0]\n",
      "g_loss 0.95978904\n",
      "step :  43\n",
      "d_loss [0.0021409 0.       ]\n",
      "d_loss_real [0.0030892903, 0.0]\n",
      "d_loss_fake [0.0011925141, 0.0]\n",
      "g_loss 0.95220554\n",
      "step :  44\n",
      "d_loss [0.00372301 0.        ]\n",
      "d_loss_real [0.006213762, 0.0]\n",
      "d_loss_fake [0.0012322483, 0.0]\n",
      "g_loss 0.9512016\n",
      "step :  45\n",
      "d_loss [0.00166318 0.        ]\n",
      "d_loss_real [0.0024841088, 0.0]\n",
      "d_loss_fake [0.00084224454, 0.0]\n",
      "g_loss 0.97167134\n",
      "step :  46\n",
      "d_loss [0.00189591 0.        ]\n",
      "d_loss_real [0.003060973, 0.0]\n",
      "d_loss_fake [0.0007308383, 0.0]\n",
      "g_loss 0.9782449\n",
      "step :  47\n",
      "d_loss [0.00083075 0.        ]\n",
      "d_loss_real [0.0012629929, 0.0]\n",
      "d_loss_fake [0.0003984972, 0.0]\n",
      "g_loss 0.99226487\n",
      "step :  48\n",
      "d_loss [0.00190827 0.        ]\n",
      "d_loss_real [0.0034760502, 0.0]\n",
      "d_loss_fake [0.00034049782, 0.0]\n",
      "g_loss 0.98454404\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-129-bed1fd8c3c1b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-126-a6929a6dbc93>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, X_train, epochs, batch_size, sample_interval, save_dir)\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m             \u001b[0mnoise\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m             \u001b[0mgen_images\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m             \u001b[0mstop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstart\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m             \u001b[0mreal_images\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mstop\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m   1167\u001b[0m                                             \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1168\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1169\u001b[1;33m                                             steps=steps)\n\u001b[0m\u001b[0;32m   1170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1171\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[1;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m    292\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 294\u001b[1;33m             \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    295\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.train(x_train,epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
