{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input,Dense,LeakyReLU,Conv2D,Conv2DTranspose,Reshape,Flatten, Dropout\n",
    "from keras.models import Model\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generator\n",
    "\n",
    "latent_dim = 32\n",
    "height = 32\n",
    "width = 32\n",
    "channels = 3\n",
    "img_row_shape = 16\n",
    "img_col_shape = 16\n",
    "img_channel_num = 128 # \n",
    "channels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_input = Input(shape=(latent_dim,))\n",
    "x = Dense(img_channel_num * img_row_shape * img_col_shape)(generator_input)\n",
    "x = LeakyReLU()(x)\n",
    "x = Reshape((img_row_shape,img_col_shape,img_channel_num))(x)\n",
    "\n",
    "x = Conv2D(256,5, padding= 'same')(x)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "x = Conv2DTranspose(256,4, strides = 2, padding='same')(x)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "x = Conv2D(256, 5, padding = 'same')(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Conv2D(256, 5, padding = 'same')(x)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "x = Conv2D(channels, 7 , activation = 'tanh',padding = 'same')(x)\n",
    "generator = Model(generator_input,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_20 (InputLayer)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 32768)             1081344   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_50 (LeakyReLU)   (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "reshape_6 (Reshape)          (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_45 (Conv2D)           (None, 16, 16, 256)       819456    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_51 (LeakyReLU)   (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTr (None, 32, 32, 256)       1048832   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_52 (LeakyReLU)   (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_46 (Conv2D)           (None, 32, 32, 256)       1638656   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_53 (LeakyReLU)   (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_47 (Conv2D)           (None, 32, 32, 256)       1638656   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_54 (LeakyReLU)   (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_48 (Conv2D)           (None, 32, 32, 3)         37635     \n",
      "=================================================================\n",
      "Total params: 6,264,579\n",
      "Trainable params: 6,264,579\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator_input = Input(shape = (width,height,channels))\n",
    "x = Conv2D(128,3)(discriminator_input)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "x = Conv2D(128,4, strides = 2)(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Conv2D(128,4, strides = 2)(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Conv2D(128,4, strides = 2)(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Flatten()(x)\n",
    "\n",
    "x = Dropout(0.4)(x)\n",
    "x = Dense(1,activation = 'sigmoid')(x)\n",
    "discriminator = Model(discriminator_input,x)\n",
    "discriminator_optimizer = RMSprop(lr = 0.0002,clipvalue = 1.0, decay = 1e-8)\n",
    "discriminator.compile(optimizer = discriminator_optimizer, loss = 'binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.trainable = False\n",
    "gan_input = Input(shape=(latent_dim,))\n",
    "gan_output = discriminator(generator(gan_input)) #ganerator\n",
    "gan = Model(gan_input, gan_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_optimizer = RMSprop(lr=0.0002,clipvalue=1.0,decay=1e-8)\n",
    "gan.compile(optimizer=gan_optimizer, loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing import image\n",
    "import os\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,y_train),(_,_) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train[y_train.flatten()==6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape((x_train.shape[0],) + \\\n",
    "                         (width,height,channels)).astype('float32')/255.\n",
    "iterations = 10000\n",
    "batch_size = 20\n",
    "save_dir = \"./frog/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ie-02\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step :  0\n",
      "d_loss 0.69322187\n",
      "a_loss 0.68189275\n",
      "step :  1\n",
      "d_loss 0.95458853\n",
      "a_loss 0.686425\n",
      "step :  2\n",
      "d_loss 0.7030105\n",
      "a_loss 1.105202\n",
      "step :  3\n",
      "d_loss 0.7478435\n",
      "a_loss 0.74288595\n",
      "step :  4\n",
      "d_loss 0.70144236\n",
      "a_loss 0.69450265\n",
      "step :  5\n",
      "d_loss 0.6631601\n",
      "a_loss 0.61311543\n",
      "step :  6\n",
      "d_loss 0.9632038\n",
      "a_loss 0.8015507\n",
      "step :  7\n",
      "d_loss 0.6754815\n",
      "a_loss 0.95023406\n",
      "step :  8\n",
      "d_loss 0.730112\n",
      "a_loss 0.7270125\n",
      "step :  9\n",
      "d_loss 0.72096056\n",
      "a_loss 0.7393047\n",
      "step :  10\n",
      "d_loss 0.66884196\n",
      "a_loss 0.6951211\n",
      "step :  11\n",
      "d_loss 0.64383936\n",
      "a_loss 0.657067\n",
      "step :  12\n",
      "d_loss 0.7228395\n",
      "a_loss 0.6442342\n",
      "step :  13\n",
      "d_loss 0.7709808\n",
      "a_loss 0.97369576\n",
      "step :  14\n",
      "d_loss 0.6504017\n",
      "a_loss 1.3812304\n",
      "step :  15\n",
      "d_loss 0.7676292\n",
      "a_loss 0.736438\n",
      "step :  16\n",
      "d_loss 0.7156118\n",
      "a_loss 0.6888987\n",
      "step :  17\n",
      "d_loss 0.6492737\n",
      "a_loss 0.6461959\n",
      "step :  18\n",
      "d_loss 0.6949375\n",
      "a_loss 0.6278658\n",
      "step :  19\n",
      "d_loss 0.7605341\n",
      "a_loss 0.9093114\n",
      "step :  20\n",
      "d_loss 0.6746925\n",
      "a_loss 0.76617944\n",
      "step :  21\n",
      "d_loss 0.6987909\n",
      "a_loss 0.6762173\n",
      "step :  22\n",
      "d_loss 0.6731154\n",
      "a_loss 0.63643354\n",
      "step :  23\n",
      "d_loss 0.67771333\n",
      "a_loss 0.73750967\n",
      "step :  24\n",
      "d_loss 0.6571304\n",
      "a_loss 0.7230986\n",
      "step :  25\n",
      "d_loss 0.67143667\n",
      "a_loss 0.598451\n",
      "step :  26\n",
      "d_loss 0.8993986\n",
      "a_loss 1.2081509\n",
      "step :  27\n",
      "d_loss 0.7462153\n",
      "a_loss 0.6935049\n",
      "step :  28\n",
      "d_loss 0.6890586\n",
      "a_loss 0.634048\n",
      "step :  29\n",
      "d_loss 0.625778\n",
      "a_loss 0.5514165\n",
      "step :  30\n",
      "d_loss 0.9022066\n",
      "a_loss 0.90633947\n",
      "step :  31\n",
      "d_loss 0.7412852\n",
      "a_loss 0.6326773\n",
      "step :  32\n",
      "d_loss 0.69639325\n",
      "a_loss 0.6135391\n",
      "step :  33\n",
      "d_loss 0.73896444\n",
      "a_loss 0.63001764\n",
      "step :  34\n",
      "d_loss 0.7537509\n",
      "a_loss 0.9044801\n",
      "step :  35\n",
      "d_loss 0.739783\n",
      "a_loss 0.6936668\n",
      "step :  36\n",
      "d_loss 0.70184886\n",
      "a_loss 0.65163505\n",
      "step :  37\n",
      "d_loss 0.687155\n",
      "a_loss 0.6145441\n",
      "step :  38\n",
      "d_loss 0.7537405\n",
      "a_loss 0.7375641\n",
      "step :  39\n",
      "d_loss 0.6884645\n",
      "a_loss 0.6767882\n",
      "step :  40\n",
      "d_loss 0.72412616\n",
      "a_loss 0.7727045\n",
      "step :  41\n",
      "d_loss 0.68190587\n",
      "a_loss 0.64079636\n",
      "step :  42\n",
      "d_loss 0.73094356\n",
      "a_loss 0.8303789\n",
      "step :  43\n",
      "d_loss 0.74668664\n",
      "a_loss 0.6265111\n",
      "step :  44\n",
      "d_loss 0.6866361\n",
      "a_loss 0.76016617\n",
      "step :  45\n",
      "d_loss 0.7140899\n",
      "a_loss 0.61634594\n",
      "step :  46\n",
      "d_loss 0.7002567\n",
      "a_loss 0.750871\n",
      "step :  47\n",
      "d_loss 0.7209116\n",
      "a_loss 0.65410674\n",
      "step :  48\n",
      "d_loss 0.68836194\n",
      "a_loss 0.70347095\n",
      "step :  49\n",
      "d_loss 0.67480516\n",
      "a_loss 0.5742339\n",
      "step :  50\n",
      "d_loss 0.83132017\n",
      "a_loss 1.8979585\n",
      "step :  51\n",
      "d_loss 1.1105812\n",
      "a_loss 0.6381855\n",
      "step :  52\n",
      "d_loss 0.6443928\n",
      "a_loss 0.5103258\n",
      "step :  53\n",
      "d_loss 0.96626747\n",
      "a_loss 1.0852622\n",
      "step :  54\n",
      "d_loss 0.77245826\n",
      "a_loss 0.6559111\n",
      "step :  55\n",
      "d_loss 0.59147877\n",
      "a_loss 0.53398687\n",
      "step :  56\n",
      "d_loss 0.73206896\n",
      "a_loss 0.6835743\n",
      "step :  57\n",
      "d_loss 0.6430934\n",
      "a_loss 0.65150696\n",
      "step :  58\n",
      "d_loss 0.73280054\n",
      "a_loss 0.58570296\n",
      "step :  59\n",
      "d_loss 0.8560909\n",
      "a_loss 2.8769844\n",
      "step :  60\n",
      "d_loss 1.1119173\n",
      "a_loss 0.70508957\n",
      "step :  61\n",
      "d_loss 0.68124145\n",
      "a_loss 0.5701017\n",
      "step :  62\n",
      "d_loss 0.61658657\n",
      "a_loss 0.52186877\n",
      "step :  63\n",
      "d_loss 0.66538996\n",
      "a_loss 0.58459187\n",
      "step :  64\n",
      "d_loss 0.7919194\n",
      "a_loss 0.92783165\n",
      "step :  65\n",
      "d_loss 0.8520109\n",
      "a_loss 0.5435749\n",
      "step :  66\n",
      "d_loss 0.79787004\n",
      "a_loss 0.7915114\n",
      "step :  67\n",
      "d_loss 0.7465045\n",
      "a_loss 0.5099999\n",
      "step :  68\n",
      "d_loss 0.8909545\n",
      "a_loss 1.030403\n",
      "step :  69\n",
      "d_loss 0.80366725\n",
      "a_loss 0.6316582\n",
      "step :  70\n",
      "d_loss 0.6672586\n",
      "a_loss 0.5455081\n",
      "step :  71\n",
      "d_loss 0.7550535\n",
      "a_loss 0.82329863\n",
      "step :  72\n",
      "d_loss 0.7468254\n",
      "a_loss 0.4503193\n",
      "step :  73\n",
      "d_loss 0.9886979\n",
      "a_loss 1.6683733\n",
      "step :  74\n",
      "d_loss 0.94689596\n",
      "a_loss 0.61595285\n",
      "step :  75\n",
      "d_loss 0.6348461\n",
      "a_loss 0.5004601\n",
      "step :  76\n",
      "d_loss 0.84272736\n",
      "a_loss 1.0489835\n",
      "step :  77\n",
      "d_loss 0.84900796\n",
      "a_loss 0.5354549\n",
      "step :  78\n",
      "d_loss 0.66254\n",
      "a_loss 0.5094687\n",
      "step :  79\n",
      "d_loss 0.8573011\n",
      "a_loss 0.53108644\n",
      "step :  80\n",
      "d_loss 0.7499684\n",
      "a_loss 0.79907537\n",
      "step :  81\n",
      "d_loss 0.8182583\n",
      "a_loss 0.4862093\n",
      "step :  82\n",
      "d_loss 0.8782445\n",
      "a_loss 1.031656\n",
      "step :  83\n",
      "d_loss 0.8235046\n",
      "a_loss 0.526959\n",
      "step :  84\n",
      "d_loss 0.74510115\n",
      "a_loss 0.59632987\n",
      "step :  85\n",
      "d_loss 0.7130871\n",
      "a_loss 0.50449955\n",
      "step :  86\n",
      "d_loss 0.81333905\n",
      "a_loss 1.2754014\n",
      "step :  87\n",
      "d_loss 0.8466259\n",
      "a_loss 0.4735609\n",
      "step :  88\n",
      "d_loss 0.7615887\n",
      "a_loss 0.833907\n",
      "step :  89\n",
      "d_loss 0.7168789\n",
      "a_loss 0.48828846\n",
      "step :  90\n",
      "d_loss 0.9120134\n",
      "a_loss 1.1555045\n",
      "step :  91\n",
      "d_loss 0.82392234\n",
      "a_loss 0.4920419\n",
      "step :  92\n",
      "d_loss 0.7685941\n",
      "a_loss 0.7420019\n",
      "step :  93\n",
      "d_loss 0.6497803\n",
      "a_loss 0.5334343\n",
      "step :  94\n",
      "d_loss 0.75776637\n",
      "a_loss 0.80692756\n",
      "step :  95\n",
      "d_loss 0.7977375\n",
      "a_loss 0.40273166\n",
      "step :  96\n",
      "d_loss 1.0292212\n",
      "a_loss 1.6980499\n",
      "step :  97\n",
      "d_loss 1.2877249\n",
      "a_loss 0.42778143\n",
      "step :  98\n",
      "d_loss 1.151725\n",
      "a_loss 1.8498758\n",
      "step :  99\n",
      "d_loss 1.3265707\n",
      "a_loss 0.5010537\n",
      "step :  100\n",
      "d_loss 0.7232534\n",
      "a_loss 0.5168046\n",
      "step :  101\n",
      "d_loss 0.67372954\n",
      "a_loss 0.6178287\n",
      "step :  102\n",
      "d_loss 0.97723544\n",
      "a_loss 0.38024396\n",
      "step :  103\n",
      "d_loss 1.1461182\n",
      "a_loss 2.7966623\n",
      "step :  104\n",
      "d_loss 1.3636984\n",
      "a_loss 0.50285804\n",
      "step :  105\n",
      "d_loss 0.7955321\n",
      "a_loss 0.51341826\n",
      "step :  106\n",
      "d_loss 0.89954245\n",
      "a_loss 0.93707645\n",
      "step :  107\n",
      "d_loss 1.0665314\n",
      "a_loss 0.36127892\n",
      "step :  108\n",
      "d_loss 1.1064695\n",
      "a_loss 1.0001693\n",
      "step :  109\n",
      "d_loss 0.6816827\n",
      "a_loss 0.6141982\n",
      "step :  110\n",
      "d_loss 0.7149582\n",
      "a_loss 0.36593527\n",
      "step :  111\n",
      "d_loss 0.95285237\n",
      "a_loss 0.7295025\n",
      "step :  112\n",
      "d_loss 0.83486766\n",
      "a_loss 0.5260156\n",
      "step :  113\n",
      "d_loss 0.8181651\n",
      "a_loss 0.66183627\n",
      "step :  114\n",
      "d_loss 0.7927904\n",
      "a_loss 0.3552107\n",
      "step :  115\n",
      "d_loss 1.2791309\n",
      "a_loss 3.6863186\n",
      "step :  116\n",
      "d_loss 2.2805073\n",
      "a_loss 0.41970366\n",
      "step :  117\n",
      "d_loss 0.8759794\n",
      "a_loss 0.4080046\n",
      "step :  118\n",
      "d_loss 0.80881244\n",
      "a_loss 0.80736005\n"
     ]
    }
   ],
   "source": [
    "start = 0 \n",
    "for step in range(iterations):\n",
    "    random_latent_vectors = np.random.normal(size=(batch_size,latent_dim))\n",
    "    generated_images = generator.predict(random_latent_vectors)\n",
    "    stop = start + batch_size\n",
    "    real_images = x_train[start : stop]\n",
    "    combined_images = np.concatenate([generated_images, real_images])\n",
    "    labels = np.concatenate([np.ones((batch_size,1)),\\\n",
    "                            np.zeros((batch_size,1))])\n",
    "    labels += 0.05 * np.random.random(labels.shape)\n",
    "    d_loss = discriminator.train_on_batch(combined_images, labels)\n",
    "    \n",
    "    random_latent_vectors = np.random.normal(size = (batch_size, latent_dim))\n",
    "    \n",
    "    misleading_targets = np.zeros((batch_size,1))\n",
    "    \n",
    "    a_loss = gan.train_on_batch(random_latent_vectors, misleading_targets)\n",
    "    \n",
    "    print(\"step : \", step)\n",
    "    print(\"d_loss\",d_loss)\n",
    "    print(\"a_loss\",a_loss)\n",
    "    start += batch_size \n",
    "    if start > len(x_train) - batch_size : \n",
    "        start =0\n",
    "    if step % 10 == 0 :\n",
    "        gan.save_weights(\"gan.h5\")\n",
    "        img = image.array_to_img(generated_images[0] * 255., scale=False)\n",
    "        img.save(os.path.join(save_dir,'generated_frog'+str(step)+\".png\"))\n",
    "        \n",
    "        img = image.array_to_img(real_images[0]*255.,scale=False)\n",
    "        img.save(os.path.join(save_dir,'real_frog'+str(step)+\".png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
