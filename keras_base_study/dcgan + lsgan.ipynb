{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input,Dense,LeakyReLU,Conv2D,Conv2DTranspose,Reshape,Flatten, Dropout\n",
    "from keras.models import Model\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generator\n",
    "\n",
    "latent_dim = 32\n",
    "height = 32\n",
    "width = 32\n",
    "channels = 3\n",
    "img_row_shape = 16\n",
    "img_col_shape = 16\n",
    "img_channel_num = 128 # \n",
    "channels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_input = Input(shape=(latent_dim,))\n",
    "x = Dense(img_channel_num * img_row_shape * img_col_shape)(generator_input)\n",
    "x = LeakyReLU()(x)\n",
    "x = Reshape((img_row_shape,img_col_shape,img_channel_num))(x)\n",
    "\n",
    "x = Conv2D(256,5, padding= 'same')(x)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "x = Conv2DTranspose(256,4, strides = 2, padding='same')(x)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "x = Conv2D(256, 5, padding = 'same')(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Conv2D(256, 5, padding = 'same')(x)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "x = Conv2D(channels, 7 , activation = 'tanh',padding = 'same')(x)\n",
    "generator = Model(generator_input,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_20 (InputLayer)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 32768)             1081344   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_50 (LeakyReLU)   (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "reshape_6 (Reshape)          (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_45 (Conv2D)           (None, 16, 16, 256)       819456    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_51 (LeakyReLU)   (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTr (None, 32, 32, 256)       1048832   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_52 (LeakyReLU)   (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_46 (Conv2D)           (None, 32, 32, 256)       1638656   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_53 (LeakyReLU)   (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_47 (Conv2D)           (None, 32, 32, 256)       1638656   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_54 (LeakyReLU)   (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_48 (Conv2D)           (None, 32, 32, 3)         37635     \n",
      "=================================================================\n",
      "Total params: 6,264,579\n",
      "Trainable params: 6,264,579\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator_input = Input(shape = (width,height,channels))\n",
    "x = Conv2D(128,3)(discriminator_input)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "x = Conv2D(128,4, strides = 2)(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Conv2D(128,4, strides = 2)(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Conv2D(128,4, strides = 2)(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Flatten()(x)\n",
    "\n",
    "x = Dropout(0.4)(x)\n",
    "x = Dense(1,activation = 'sigmoid')(x)\n",
    "discriminator = Model(discriminator_input,x)\n",
    "discriminator_optimizer = RMSprop(lr = 0.0002,clipvalue = 1.0, decay = 1e-8)\n",
    "discriminator.compile(optimizer = discriminator_optimizer, loss = 'binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.trainable = False\n",
    "gan_input = Input(shape=(latent_dim,))\n",
    "gan_output = discriminator(generator(gan_input)) #ganerator\n",
    "gan = Model(gan_input, gan_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_optimizer = RMSprop(lr=0.0002,clipvalue=1.0,decay=1e-8)\n",
    "gan.compile(optimizer=gan_optimizer, loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing import image\n",
    "import os\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,y_train),(_,_) = cifar10.load_data()\n",
    "x_train = x_train[y_train.flatten()==6]\n",
    "x_train = x_train.reshape((x_train.shape[0],) + \\\n",
    "                         (width,height,channels)).astype('float32')/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "iterations = 10000\n",
    "batch_size = 20\n",
    "save_dir = \"./frog/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ie-02\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step :  0\n",
      "d_loss 0.69322187\n",
      "a_loss 0.68189275\n",
      "step :  1\n",
      "d_loss 0.95458853\n",
      "a_loss 0.686425\n",
      "step :  2\n",
      "d_loss 0.7030105\n",
      "a_loss 1.105202\n",
      "step :  3\n",
      "d_loss 0.7478435\n",
      "a_loss 0.74288595\n",
      "step :  4\n",
      "d_loss 0.70144236\n",
      "a_loss 0.69450265\n",
      "step :  5\n",
      "d_loss 0.6631601\n",
      "a_loss 0.61311543\n",
      "step :  6\n",
      "d_loss 0.9632038\n",
      "a_loss 0.8015507\n",
      "step :  7\n",
      "d_loss 0.6754815\n",
      "a_loss 0.95023406\n",
      "step :  8\n",
      "d_loss 0.730112\n",
      "a_loss 0.7270125\n",
      "step :  9\n",
      "d_loss 0.72096056\n",
      "a_loss 0.7393047\n",
      "step :  10\n",
      "d_loss 0.66884196\n",
      "a_loss 0.6951211\n",
      "step :  11\n",
      "d_loss 0.64383936\n",
      "a_loss 0.657067\n",
      "step :  12\n",
      "d_loss 0.7228395\n",
      "a_loss 0.6442342\n",
      "step :  13\n",
      "d_loss 0.7709808\n",
      "a_loss 0.97369576\n",
      "step :  14\n",
      "d_loss 0.6504017\n",
      "a_loss 1.3812304\n",
      "step :  15\n",
      "d_loss 0.7676292\n",
      "a_loss 0.736438\n",
      "step :  16\n",
      "d_loss 0.7156118\n",
      "a_loss 0.6888987\n",
      "step :  17\n",
      "d_loss 0.6492737\n",
      "a_loss 0.6461959\n",
      "step :  18\n",
      "d_loss 0.6949375\n",
      "a_loss 0.6278658\n",
      "step :  19\n",
      "d_loss 0.7605341\n",
      "a_loss 0.9093114\n",
      "step :  20\n",
      "d_loss 0.6746925\n",
      "a_loss 0.76617944\n",
      "step :  21\n",
      "d_loss 0.6987909\n",
      "a_loss 0.6762173\n",
      "step :  22\n",
      "d_loss 0.6731154\n",
      "a_loss 0.63643354\n",
      "step :  23\n",
      "d_loss 0.67771333\n",
      "a_loss 0.73750967\n",
      "step :  24\n",
      "d_loss 0.6571304\n",
      "a_loss 0.7230986\n",
      "step :  25\n",
      "d_loss 0.67143667\n",
      "a_loss 0.598451\n",
      "step :  26\n",
      "d_loss 0.8993986\n",
      "a_loss 1.2081509\n",
      "step :  27\n",
      "d_loss 0.7462153\n",
      "a_loss 0.6935049\n",
      "step :  28\n",
      "d_loss 0.6890586\n",
      "a_loss 0.634048\n",
      "step :  29\n",
      "d_loss 0.625778\n",
      "a_loss 0.5514165\n",
      "step :  30\n",
      "d_loss 0.9022066\n",
      "a_loss 0.90633947\n",
      "step :  31\n",
      "d_loss 0.7412852\n",
      "a_loss 0.6326773\n",
      "step :  32\n",
      "d_loss 0.69639325\n",
      "a_loss 0.6135391\n",
      "step :  33\n",
      "d_loss 0.73896444\n",
      "a_loss 0.63001764\n",
      "step :  34\n",
      "d_loss 0.7537509\n",
      "a_loss 0.9044801\n",
      "step :  35\n",
      "d_loss 0.739783\n",
      "a_loss 0.6936668\n",
      "step :  36\n",
      "d_loss 0.70184886\n",
      "a_loss 0.65163505\n",
      "step :  37\n",
      "d_loss 0.687155\n",
      "a_loss 0.6145441\n",
      "step :  38\n",
      "d_loss 0.7537405\n",
      "a_loss 0.7375641\n",
      "step :  39\n",
      "d_loss 0.6884645\n",
      "a_loss 0.6767882\n",
      "step :  40\n",
      "d_loss 0.72412616\n",
      "a_loss 0.7727045\n",
      "step :  41\n",
      "d_loss 0.68190587\n",
      "a_loss 0.64079636\n",
      "step :  42\n",
      "d_loss 0.73094356\n",
      "a_loss 0.8303789\n",
      "step :  43\n",
      "d_loss 0.74668664\n",
      "a_loss 0.6265111\n",
      "step :  44\n",
      "d_loss 0.6866361\n",
      "a_loss 0.76016617\n",
      "step :  45\n",
      "d_loss 0.7140899\n",
      "a_loss 0.61634594\n",
      "step :  46\n",
      "d_loss 0.7002567\n",
      "a_loss 0.750871\n",
      "step :  47\n",
      "d_loss 0.7209116\n",
      "a_loss 0.65410674\n",
      "step :  48\n",
      "d_loss 0.68836194\n",
      "a_loss 0.70347095\n",
      "step :  49\n",
      "d_loss 0.67480516\n",
      "a_loss 0.5742339\n",
      "step :  50\n",
      "d_loss 0.83132017\n",
      "a_loss 1.8979585\n",
      "step :  51\n",
      "d_loss 1.1105812\n",
      "a_loss 0.6381855\n",
      "step :  52\n",
      "d_loss 0.6443928\n",
      "a_loss 0.5103258\n",
      "step :  53\n",
      "d_loss 0.96626747\n",
      "a_loss 1.0852622\n",
      "step :  54\n",
      "d_loss 0.77245826\n",
      "a_loss 0.6559111\n",
      "step :  55\n",
      "d_loss 0.59147877\n",
      "a_loss 0.53398687\n",
      "step :  56\n",
      "d_loss 0.73206896\n",
      "a_loss 0.6835743\n",
      "step :  57\n",
      "d_loss 0.6430934\n",
      "a_loss 0.65150696\n",
      "step :  58\n",
      "d_loss 0.73280054\n",
      "a_loss 0.58570296\n",
      "step :  59\n",
      "d_loss 0.8560909\n",
      "a_loss 2.8769844\n",
      "step :  60\n",
      "d_loss 1.1119173\n",
      "a_loss 0.70508957\n",
      "step :  61\n",
      "d_loss 0.68124145\n",
      "a_loss 0.5701017\n",
      "step :  62\n",
      "d_loss 0.61658657\n",
      "a_loss 0.52186877\n",
      "step :  63\n",
      "d_loss 0.66538996\n",
      "a_loss 0.58459187\n",
      "step :  64\n",
      "d_loss 0.7919194\n",
      "a_loss 0.92783165\n",
      "step :  65\n",
      "d_loss 0.8520109\n",
      "a_loss 0.5435749\n",
      "step :  66\n",
      "d_loss 0.79787004\n",
      "a_loss 0.7915114\n",
      "step :  67\n",
      "d_loss 0.7465045\n",
      "a_loss 0.5099999\n",
      "step :  68\n",
      "d_loss 0.8909545\n",
      "a_loss 1.030403\n",
      "step :  69\n",
      "d_loss 0.80366725\n",
      "a_loss 0.6316582\n",
      "step :  70\n",
      "d_loss 0.6672586\n",
      "a_loss 0.5455081\n",
      "step :  71\n",
      "d_loss 0.7550535\n",
      "a_loss 0.82329863\n",
      "step :  72\n",
      "d_loss 0.7468254\n",
      "a_loss 0.4503193\n",
      "step :  73\n",
      "d_loss 0.9886979\n",
      "a_loss 1.6683733\n",
      "step :  74\n",
      "d_loss 0.94689596\n",
      "a_loss 0.61595285\n",
      "step :  75\n",
      "d_loss 0.6348461\n",
      "a_loss 0.5004601\n",
      "step :  76\n",
      "d_loss 0.84272736\n",
      "a_loss 1.0489835\n",
      "step :  77\n",
      "d_loss 0.84900796\n",
      "a_loss 0.5354549\n",
      "step :  78\n",
      "d_loss 0.66254\n",
      "a_loss 0.5094687\n",
      "step :  79\n",
      "d_loss 0.8573011\n",
      "a_loss 0.53108644\n",
      "step :  80\n",
      "d_loss 0.7499684\n",
      "a_loss 0.79907537\n",
      "step :  81\n",
      "d_loss 0.8182583\n",
      "a_loss 0.4862093\n",
      "step :  82\n",
      "d_loss 0.8782445\n",
      "a_loss 1.031656\n",
      "step :  83\n",
      "d_loss 0.8235046\n",
      "a_loss 0.526959\n",
      "step :  84\n",
      "d_loss 0.74510115\n",
      "a_loss 0.59632987\n",
      "step :  85\n",
      "d_loss 0.7130871\n",
      "a_loss 0.50449955\n",
      "step :  86\n",
      "d_loss 0.81333905\n",
      "a_loss 1.2754014\n",
      "step :  87\n",
      "d_loss 0.8466259\n",
      "a_loss 0.4735609\n",
      "step :  88\n",
      "d_loss 0.7615887\n",
      "a_loss 0.833907\n",
      "step :  89\n",
      "d_loss 0.7168789\n",
      "a_loss 0.48828846\n",
      "step :  90\n",
      "d_loss 0.9120134\n",
      "a_loss 1.1555045\n",
      "step :  91\n",
      "d_loss 0.82392234\n",
      "a_loss 0.4920419\n",
      "step :  92\n",
      "d_loss 0.7685941\n",
      "a_loss 0.7420019\n",
      "step :  93\n",
      "d_loss 0.6497803\n",
      "a_loss 0.5334343\n",
      "step :  94\n",
      "d_loss 0.75776637\n",
      "a_loss 0.80692756\n",
      "step :  95\n",
      "d_loss 0.7977375\n",
      "a_loss 0.40273166\n",
      "step :  96\n",
      "d_loss 1.0292212\n",
      "a_loss 1.6980499\n",
      "step :  97\n",
      "d_loss 1.2877249\n",
      "a_loss 0.42778143\n",
      "step :  98\n",
      "d_loss 1.151725\n",
      "a_loss 1.8498758\n",
      "step :  99\n",
      "d_loss 1.3265707\n",
      "a_loss 0.5010537\n",
      "step :  100\n",
      "d_loss 0.7232534\n",
      "a_loss 0.5168046\n",
      "step :  101\n",
      "d_loss 0.67372954\n",
      "a_loss 0.6178287\n",
      "step :  102\n",
      "d_loss 0.97723544\n",
      "a_loss 0.38024396\n",
      "step :  103\n",
      "d_loss 1.1461182\n",
      "a_loss 2.7966623\n",
      "step :  104\n",
      "d_loss 1.3636984\n",
      "a_loss 0.50285804\n",
      "step :  105\n",
      "d_loss 0.7955321\n",
      "a_loss 0.51341826\n",
      "step :  106\n",
      "d_loss 0.89954245\n",
      "a_loss 0.93707645\n",
      "step :  107\n",
      "d_loss 1.0665314\n",
      "a_loss 0.36127892\n",
      "step :  108\n",
      "d_loss 1.1064695\n",
      "a_loss 1.0001693\n",
      "step :  109\n",
      "d_loss 0.6816827\n",
      "a_loss 0.6141982\n",
      "step :  110\n",
      "d_loss 0.7149582\n",
      "a_loss 0.36593527\n",
      "step :  111\n",
      "d_loss 0.95285237\n",
      "a_loss 0.7295025\n",
      "step :  112\n",
      "d_loss 0.83486766\n",
      "a_loss 0.5260156\n",
      "step :  113\n",
      "d_loss 0.8181651\n",
      "a_loss 0.66183627\n",
      "step :  114\n",
      "d_loss 0.7927904\n",
      "a_loss 0.3552107\n",
      "step :  115\n",
      "d_loss 1.2791309\n",
      "a_loss 3.6863186\n",
      "step :  116\n",
      "d_loss 2.2805073\n",
      "a_loss 0.41970366\n",
      "step :  117\n",
      "d_loss 0.8759794\n",
      "a_loss 0.4080046\n",
      "step :  118\n",
      "d_loss 0.80881244\n",
      "a_loss 0.80736005\n",
      "step :  119\n",
      "d_loss 0.97347385\n",
      "a_loss 0.37149936\n",
      "step :  120\n",
      "d_loss 1.0763185\n",
      "a_loss 1.247429\n",
      "step :  121\n",
      "d_loss 0.9201816\n",
      "a_loss 0.41219702\n",
      "step :  122\n",
      "d_loss 0.79602736\n",
      "a_loss 0.7323413\n",
      "step :  123\n",
      "d_loss 0.81804055\n",
      "a_loss 0.2546736\n",
      "step :  124\n",
      "d_loss 1.2630527\n",
      "a_loss 1.3232257\n",
      "step :  125\n",
      "d_loss 1.3903654\n",
      "a_loss 0.24218602\n",
      "step :  126\n",
      "d_loss 1.1421108\n",
      "a_loss 0.42867613\n",
      "step :  127\n",
      "d_loss 0.8289688\n",
      "a_loss 0.63097864\n",
      "step :  128\n",
      "d_loss 0.6807679\n",
      "a_loss 0.6511955\n",
      "step :  129\n",
      "d_loss 0.7243173\n",
      "a_loss 0.5913436\n",
      "step :  130\n",
      "d_loss 1.1258659\n",
      "a_loss 0.3804409\n",
      "step :  131\n",
      "d_loss 1.1416857\n",
      "a_loss 1.8995327\n",
      "step :  132\n",
      "d_loss 1.9182777\n",
      "a_loss 0.21211112\n",
      "step :  133\n",
      "d_loss 1.2867914\n",
      "a_loss 0.46422625\n",
      "step :  134\n",
      "d_loss 0.95565975\n",
      "a_loss 0.77230674\n",
      "step :  135\n",
      "d_loss 0.755792\n",
      "a_loss 0.39181978\n",
      "step :  136\n",
      "d_loss 1.0407674\n",
      "a_loss 1.0727981\n",
      "step :  137\n",
      "d_loss 1.4071871\n",
      "a_loss 0.124426045\n",
      "step :  138\n",
      "d_loss 1.6893775\n",
      "a_loss 0.3046123\n",
      "step :  139\n",
      "d_loss 1.1478916\n",
      "a_loss 1.2305634\n",
      "step :  140\n",
      "d_loss 1.3739865\n",
      "a_loss 0.18784064\n",
      "step :  141\n",
      "d_loss 1.5162233\n",
      "a_loss 0.32155293\n",
      "step :  142\n",
      "d_loss 0.9470097\n",
      "a_loss 0.9528681\n",
      "step :  143\n",
      "d_loss 1.4889057\n",
      "a_loss 0.08669927\n",
      "step :  144\n",
      "d_loss 2.1161265\n",
      "a_loss 0.5893563\n",
      "step :  145\n",
      "d_loss 1.3438828\n",
      "a_loss 0.042551197\n",
      "step :  146\n",
      "d_loss 3.352864\n",
      "a_loss 2.5477507\n",
      "step :  147\n",
      "d_loss 2.2051344\n",
      "a_loss 0.23072526\n",
      "step :  148\n",
      "d_loss 1.7244136\n",
      "a_loss 0.2975287\n",
      "step :  149\n",
      "d_loss 1.9878061\n",
      "a_loss 2.4501386\n",
      "step :  150\n",
      "d_loss 3.034041\n",
      "a_loss 0.27601045\n",
      "step :  151\n",
      "d_loss 1.2169269\n",
      "a_loss 0.25810736\n",
      "step :  152\n",
      "d_loss 1.1582687\n",
      "a_loss 0.5320412\n",
      "step :  153\n",
      "d_loss 0.967182\n",
      "a_loss 0.4793211\n",
      "step :  154\n",
      "d_loss 1.085195\n",
      "a_loss 0.11069977\n",
      "step :  155\n",
      "d_loss 1.805574\n",
      "a_loss 1.5413897\n",
      "step :  156\n",
      "d_loss 1.9079326\n",
      "a_loss 0.16459927\n",
      "step :  157\n",
      "d_loss 1.656916\n",
      "a_loss 0.23686738\n",
      "step :  158\n",
      "d_loss 1.2139655\n",
      "a_loss 0.5747756\n",
      "step :  159\n",
      "d_loss 1.3203553\n",
      "a_loss 0.18805638\n",
      "step :  160\n",
      "d_loss 1.7830807\n",
      "a_loss 0.97362614\n",
      "step :  161\n",
      "d_loss 1.3635466\n",
      "a_loss 0.0788133\n",
      "step :  162\n",
      "d_loss 1.8208557\n",
      "a_loss 0.5634823\n",
      "step :  163\n",
      "d_loss 1.0930228\n",
      "a_loss 0.5556162\n",
      "step :  164\n",
      "d_loss 1.2012683\n",
      "a_loss 0.5746026\n",
      "step :  165\n",
      "d_loss 1.1705827\n",
      "a_loss 0.22802976\n",
      "step :  166\n",
      "d_loss 1.6421051\n",
      "a_loss 4.1141644\n",
      "step :  167\n",
      "d_loss 4.1709185\n",
      "a_loss 0.17735529\n",
      "step :  168\n",
      "d_loss 1.5285794\n",
      "a_loss 0.20734477\n",
      "step :  169\n",
      "d_loss 1.6062412\n",
      "a_loss 0.8749552\n",
      "step :  170\n",
      "d_loss 1.4720978\n",
      "a_loss 0.0662175\n",
      "step :  171\n",
      "d_loss 1.9323088\n",
      "a_loss 0.2390475\n",
      "step :  172\n",
      "d_loss 1.5841621\n",
      "a_loss 1.234433\n",
      "step :  173\n",
      "d_loss 1.3266885\n",
      "a_loss 0.20335181\n",
      "step :  174\n",
      "d_loss 1.3523953\n",
      "a_loss 0.26814407\n",
      "step :  175\n",
      "d_loss 1.0563759\n",
      "a_loss 0.65710795\n",
      "step :  176\n",
      "d_loss 0.8779314\n",
      "a_loss 0.47006464\n",
      "step :  177\n",
      "d_loss 0.90065783\n",
      "a_loss 0.47676188\n",
      "step :  178\n",
      "d_loss 0.8735687\n",
      "a_loss 0.3096668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step :  179\n",
      "d_loss 1.330062\n",
      "a_loss 1.5066023\n",
      "step :  180\n",
      "d_loss 1.6709007\n",
      "a_loss 0.0910425\n",
      "step :  181\n",
      "d_loss 1.8235295\n",
      "a_loss 0.24747822\n",
      "step :  182\n",
      "d_loss 1.1330538\n",
      "a_loss 0.7855701\n",
      "step :  183\n",
      "d_loss 1.1382055\n",
      "a_loss 0.045762062\n",
      "step :  184\n",
      "d_loss 2.2863827\n",
      "a_loss 0.45409274\n",
      "step :  185\n",
      "d_loss 1.5114813\n",
      "a_loss 0.12609346\n",
      "step :  186\n",
      "d_loss 2.250484\n",
      "a_loss 4.0958395\n",
      "step :  187\n",
      "d_loss 5.2505307\n",
      "a_loss 0.13764007\n",
      "step :  188\n",
      "d_loss 2.3108432\n",
      "a_loss 0.17404574\n",
      "step :  189\n",
      "d_loss 1.7047154\n",
      "a_loss 2.7697742\n",
      "step :  190\n",
      "d_loss 4.1864977\n",
      "a_loss 0.16017486\n",
      "step :  191\n",
      "d_loss 1.3759648\n",
      "a_loss 0.20644799\n",
      "step :  192\n",
      "d_loss 1.4145163\n",
      "a_loss 0.31277746\n",
      "step :  193\n",
      "d_loss 1.3927205\n",
      "a_loss 0.260949\n",
      "step :  194\n",
      "d_loss 1.6664807\n",
      "a_loss 0.86240256\n",
      "step :  195\n",
      "d_loss 1.6986492\n",
      "a_loss 0.13060899\n",
      "step :  196\n",
      "d_loss 1.6860063\n",
      "a_loss 0.26846984\n",
      "step :  197\n",
      "d_loss 1.3478934\n",
      "a_loss 1.4319645\n",
      "step :  198\n",
      "d_loss 3.9238155\n",
      "a_loss 0.048028313\n",
      "step :  199\n",
      "d_loss 2.2828414\n",
      "a_loss 0.13607141\n",
      "step :  200\n",
      "d_loss 1.7478584\n",
      "a_loss 0.24590032\n",
      "step :  201\n",
      "d_loss 1.626339\n",
      "a_loss 0.5348364\n",
      "step :  202\n",
      "d_loss 1.6800396\n",
      "a_loss 0.15401119\n",
      "step :  203\n",
      "d_loss 2.33362\n",
      "a_loss 1.1967065\n",
      "step :  204\n",
      "d_loss 1.2534504\n",
      "a_loss 0.11803901\n",
      "step :  205\n",
      "d_loss 1.8837208\n",
      "a_loss 0.20909365\n",
      "step :  206\n",
      "d_loss 1.3678643\n",
      "a_loss 0.7185497\n",
      "step :  207\n",
      "d_loss 2.0922377\n",
      "a_loss 0.06071045\n",
      "step :  208\n",
      "d_loss 2.463473\n",
      "a_loss 0.35125425\n",
      "step :  209\n",
      "d_loss 1.481901\n",
      "a_loss 0.92258537\n",
      "step :  210\n",
      "d_loss 1.9329838\n",
      "a_loss 0.06572808\n",
      "step :  211\n",
      "d_loss 2.8986435\n",
      "a_loss 0.3206161\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-93-fe190c0c02fb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mmisleading_targets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0ma_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_latent_vectors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmisleading_targets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"step : \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1217\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1218\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start = 0 \n",
    "for step in range(iterations):\n",
    "    random_latent_vectors = np.random.normal(size=(batch_size,latent_dim))\n",
    "    generated_images = generator.predict(random_latent_vectors)\n",
    "    stop = start + batch_size\n",
    "    real_images = x_train[start : stop]\n",
    "    combined_images = np.concatenate([generated_images, real_images])\n",
    "    labels = np.concatenate([np.ones((batch_size,1)),\\\n",
    "                            np.zeros((batch_size,1))])\n",
    "    labels += 0.05 * np.random.random(labels.shape)\n",
    "    d_loss = discriminator.train_on_batch(combined_images, labels)\n",
    "    \n",
    "    random_latent_vectors = np.random.normal(size = (batch_size, latent_dim))\n",
    "    \n",
    "    misleading_targets = np.zeros((batch_size,1))\n",
    "    \n",
    "    a_loss = gan.train_on_batch(random_latent_vectors, misleading_targets)\n",
    "    \n",
    "    print(\"step : \", step)\n",
    "    print(\"d_loss\",d_loss)\n",
    "    print(\"a_loss\",a_loss)\n",
    "    start += batch_size \n",
    "    if start > len(x_train) - batch_size : \n",
    "        start =0\n",
    "    if step % 10 == 0 :\n",
    "        gan.save_weights(\"gan.h5\")\n",
    "        img = image.array_to_img(generated_images[0] * 255., scale=False)\n",
    "        img.save(os.path.join(save_dir,'generated_frog'+str(step)+\".png\"))\n",
    "        \n",
    "        img = image.array_to_img(real_images[0]*255.,scale=False)\n",
    "        img.save(os.path.join(save_dir,'real_frog'+str(step)+\".png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 9, 7, 2, 5, 3, 6, 5, 5, 0, 7, 6, 7, 2, 0, 4, 6, 3, 5, 2])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randint(0, 10, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSGAN():\n",
    "    def __init__(self):\n",
    "        self.latent_dim = 32\n",
    "        self.img_channel_num = 128 #generator 에서 생성될 channel num\n",
    "        self.img_row_shape = 16 #generator 에서 생성될 row\n",
    "        self.img_col_shape = 16 #generator 에서 생성될 col\n",
    "        self.output_channels = 3 #generator 에서 나올 channels 당연히 3\n",
    "        \n",
    "        self.row = 32 #discriminator에 들어갈 row shape = generator의 output\n",
    "        self.col = 32 #discriminator에 들어갈 col shape\n",
    "        self.generator = self.build_generator()\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator_optimizer = Adam(lr=0.0002)\n",
    "        self.gan_optimizer = Adam(lr =0.0002)\n",
    "        self.discriminator.compile(loss = 'mse', optimizer = self.discriminator_optimizer,\\\n",
    "                                  metrics = ['accuracy'])\n",
    "        \n",
    "        self.discriminator.trainable = False\n",
    "        \n",
    "        gan_input = Input(shape=(self.latent_dim,))\n",
    "        gan_output = self.discriminator(self.generator(gan_input))\n",
    "        self.gan = Model(gan_input,gan_output)\n",
    "        self.gan.compile(loss = 'mse',optimizer = self.gan_optimizer)\n",
    "        \n",
    "    def build_generator(self):\n",
    "        generator_input = Input(shape=(self.latent_dim,))\n",
    "        x = Dense(self.img_channel_num * self.img_row_shape * self.img_col_shape)(generator_input)\n",
    "        x = LeakyReLU()(x)            \n",
    "        x = Reshape((self.img_row_shape,self.img_col_shape,self.img_channel_num))(x)\n",
    "\n",
    "        x = Conv2D(256,5, padding= 'same')(x)\n",
    "        x = LeakyReLU()(x)\n",
    "\n",
    "        x = Conv2DTranspose(256,4, strides = 2, padding='same')(x)\n",
    "        x = LeakyReLU()(x)\n",
    "\n",
    "        x = Conv2D(256, 5, padding = 'same')(x)\n",
    "        x = LeakyReLU()(x)\n",
    "        x = Conv2D(256, 5, padding = 'same')(x)\n",
    "        x = LeakyReLU()(x)\n",
    "        x = Conv2D(self.output_channels, 7 , activation = 'tanh',padding = 'same')(x)\n",
    "        generator = Model(generator_input,x)\n",
    "        return generator\n",
    "    \n",
    "    def build_discriminator(self):\n",
    "        discriminator_input = Input(shape = (self.row,self.col,self.output_channels))\n",
    "        x = Conv2D(128,3)(discriminator_input)\n",
    "        x = LeakyReLU()(x)\n",
    "\n",
    "        x = Conv2D(128,4, strides = 2)(x)\n",
    "        x = LeakyReLU()(x)\n",
    "        x = Conv2D(128,4, strides = 2)(x)\n",
    "        x = LeakyReLU()(x)\n",
    "        x = Conv2D(128,4, strides = 2)(x)\n",
    "        x = LeakyReLU()(x)\n",
    "        x = Flatten()(x)\n",
    "\n",
    "        x = Dropout(0.4)(x)\n",
    "        x = Dense(1,activation = 'sigmoid')(x)\n",
    "        discriminator = Model(discriminator_input,x)\n",
    "        return discriminator\n",
    "        \n",
    "    def train(self, X_train,epochs, batch_size=128, sample_interval=50,save_dir = \"./lsgan_frog/\"):\n",
    "\n",
    "        # Rescale -1 to 1\n",
    "        X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = np.ones((batch_size, 1))\n",
    "        valid += 0.05 * np.random.random(valid.shape)\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "        fake += 0.05 * np.random.random(fake.shape)\n",
    "        start = 0\n",
    "        for step in range(iterations):\n",
    "            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "            gen_images = self.generator.predict(noise)\n",
    "            stop = start + batch_size\n",
    "            real_images = X_train[start : stop]\n",
    "            #combined_images = np.concatenate([generated_images, real_images])\n",
    "            #combined_labels = np.concatenate([fake,valid])\n",
    "            #combined_labels += 0.05 * np.random.random(combined_labels.shape)\n",
    "            \n",
    "            d_loss_real = self.discriminator.train_on_batch(real_images, valid)\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_images, fake)\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "            \n",
    "            g_loss = self.gan.train_on_batch(noise, valid)\n",
    "            \n",
    "            print(\"step : \", step)\n",
    "            print(\"d_loss\",d_loss)\n",
    "            print(\"d_loss_real\",d_loss_real)\n",
    "            print(\"d_loss_fake\",d_loss_fake)\n",
    "            print(\"g_loss\",g_loss)\n",
    "            start += batch_size \n",
    "            if start > len(x_train) - batch_size : \n",
    "                start =0\n",
    "            if step % 10 == 0 :\n",
    "                gan.save_weights(\"lsgan.h5\")\n",
    "                img = image.array_to_img((generated_images[0] * 127.5)+127.5, scale=False)\n",
    "                img.save(os.path.join(save_dir,'generated_frog_'+str(step)+\".png\"))\n",
    "\n",
    "                img = image.array_to_img((real_images[0] * 127.5) + 127.5,scale=False)\n",
    "                img.save(os.path.join(save_dir,'real_frog_'+str(step)+\".png\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=32x32 at 0x22C3B2CE6A0>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.array_to_img(x_train[5]*255,scale=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSGAN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,y_train),(_,_) = cifar10.load_data()\n",
    "x_train = x_train[y_train.flatten()==6]\n",
    "x_train = x_train.reshape((x_train.shape[0],) + \\\n",
    "                         (width,height,channels)).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ie-02\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step :  0\n",
      "d_loss [0.24976125 0.        ]\n",
      "d_loss_real [0.27296102, 0.0]\n",
      "d_loss_fake [0.2265615, 0.0]\n",
      "g_loss 0.27339375\n",
      "step :  1\n",
      "d_loss [0.2063446 0.       ]\n",
      "d_loss_real [0.17054757, 0.0]\n",
      "d_loss_fake [0.24214165, 0.0]\n",
      "g_loss 0.25287193\n",
      "step :  2\n",
      "d_loss [0.21727777 0.        ]\n",
      "d_loss_real [0.09385974, 0.0]\n",
      "d_loss_fake [0.3406958, 0.0]\n",
      "g_loss 0.17471339\n",
      "step :  3\n",
      "d_loss [0.3230943 0.       ]\n",
      "d_loss_real [0.052498315, 0.0]\n",
      "d_loss_fake [0.5936903, 0.0]\n",
      "g_loss 0.07352994\n",
      "step :  4\n",
      "d_loss [0.390272 0.      ]\n",
      "d_loss_real [0.03942565, 0.0]\n",
      "d_loss_fake [0.7411183, 0.0]\n",
      "g_loss 0.0475699\n",
      "step :  5\n",
      "d_loss [0.3803041 0.       ]\n",
      "d_loss_real [0.04680335, 0.0]\n",
      "d_loss_fake [0.71380484, 0.0]\n",
      "g_loss 0.07615239\n",
      "step :  6\n",
      "d_loss [0.29621056 0.        ]\n",
      "d_loss_real [0.06622911, 0.0]\n",
      "d_loss_fake [0.526192, 0.0]\n",
      "g_loss 0.22623888\n",
      "step :  7\n",
      "d_loss [0.13002266 0.        ]\n",
      "d_loss_real [0.10994684, 0.0]\n",
      "d_loss_fake [0.15009847, 0.0]\n",
      "g_loss 0.58909345\n",
      "step :  8\n",
      "d_loss [0.0966242 0.       ]\n",
      "d_loss_real [0.16927621, 0.0]\n",
      "d_loss_fake [0.023972195, 0.0]\n",
      "g_loss 0.8316996\n",
      "step :  9\n",
      "d_loss [0.07915783 0.        ]\n",
      "d_loss_real [0.15493378, 0.0]\n",
      "d_loss_fake [0.0033818856, 0.0]\n",
      "g_loss 0.9323217\n",
      "step :  10\n",
      "d_loss [0.10051749 0.        ]\n",
      "d_loss_real [0.200234, 0.0]\n",
      "d_loss_fake [0.0008009808, 0.0]\n",
      "g_loss 0.9717451\n",
      "step :  11\n",
      "d_loss [0.09607375 0.        ]\n",
      "d_loss_real [0.1916278, 0.0]\n",
      "d_loss_fake [0.0005197085, 0.0]\n",
      "g_loss 0.9747993\n"
     ]
    }
   ],
   "source": [
    "model.train(x_train,epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
