{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input,Dense,LeakyReLU,Conv2D,Conv2DTranspose,Reshape,Flatten, Dropout\n",
    "from keras.models import Model\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generator\n",
    "\n",
    "latent_dim = 32\n",
    "height = 32\n",
    "width = 32\n",
    "channels = 3\n",
    "img_row_shape = 16\n",
    "img_col_shape = 16\n",
    "img_channel_num = 128 # \n",
    "channels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_input = Input(shape=(latent_dim,))\n",
    "x = Dense(img_channel_num * img_row_shape * img_col_shape)(generator_input)\n",
    "x = LeakyReLU()(x)\n",
    "x = Reshape((img_row_shape,img_col_shape,img_channel_num))(x)\n",
    "\n",
    "x = Conv2D(256,5, padding= 'same')(x)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "x = Conv2DTranspose(256,4, strides = 2, padding='same')(x)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "x = Conv2D(256, 5, padding = 'same')(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Conv2D(256, 5, padding = 'same')(x)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "x = Conv2D(channels, 7 , activation = 'tanh',padding = 'same')(x)\n",
    "generator = Model(generator_input,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_20 (InputLayer)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 32768)             1081344   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_50 (LeakyReLU)   (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "reshape_6 (Reshape)          (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_45 (Conv2D)           (None, 16, 16, 256)       819456    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_51 (LeakyReLU)   (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTr (None, 32, 32, 256)       1048832   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_52 (LeakyReLU)   (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_46 (Conv2D)           (None, 32, 32, 256)       1638656   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_53 (LeakyReLU)   (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_47 (Conv2D)           (None, 32, 32, 256)       1638656   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_54 (LeakyReLU)   (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_48 (Conv2D)           (None, 32, 32, 3)         37635     \n",
      "=================================================================\n",
      "Total params: 6,264,579\n",
      "Trainable params: 6,264,579\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator_input = Input(shape = (width,height,channels))\n",
    "x = Conv2D(128,3)(discriminator_input)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "x = Conv2D(128,4, strides = 2)(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Conv2D(128,4, strides = 2)(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Conv2D(128,4, strides = 2)(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Flatten()(x)\n",
    "\n",
    "x = Dropout(0.4)(x)\n",
    "x = Dense(1,activation = 'sigmoid')(x)\n",
    "discriminator = Model(discriminator_input,x)\n",
    "discriminator_optimizer = RMSprop(lr = 0.0002,clipvalue = 1.0, decay = 1e-8)\n",
    "discriminator.compile(optimizer = discriminator_optimizer, loss = 'binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.trainable = False\n",
    "gan_input = Input(shape=(latent_dim,))\n",
    "gan_output = discriminator(generator(gan_input)) #ganerator\n",
    "gan = Model(gan_input, gan_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_optimizer = RMSprop(lr=0.0002,clipvalue=1.0,decay=1e-8)\n",
    "gan.compile(optimizer=gan_optimizer, loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing import image\n",
    "import os\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,y_train),(_,_) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train[y_train.flatten()==6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape((x_train.shape[0],) + \\\n",
    "                         (width,height,channels)).astype('float32')/255.\n",
    "iterations = 10000\n",
    "batch_size = 20\n",
    "save_dir = \"./frog/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ie-02\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step :  0\n",
      "d_loss 0.69322187\n",
      "a_loss 0.68189275\n",
      "step :  1\n",
      "d_loss 0.95458853\n",
      "a_loss 0.686425\n",
      "step :  2\n",
      "d_loss 0.7030105\n",
      "a_loss 1.105202\n",
      "step :  3\n",
      "d_loss 0.7478435\n",
      "a_loss 0.74288595\n",
      "step :  4\n",
      "d_loss 0.70144236\n",
      "a_loss 0.69450265\n",
      "step :  5\n",
      "d_loss 0.6631601\n",
      "a_loss 0.61311543\n",
      "step :  6\n",
      "d_loss 0.9632038\n",
      "a_loss 0.8015507\n",
      "step :  7\n",
      "d_loss 0.6754815\n",
      "a_loss 0.95023406\n",
      "step :  8\n",
      "d_loss 0.730112\n",
      "a_loss 0.7270125\n",
      "step :  9\n",
      "d_loss 0.72096056\n",
      "a_loss 0.7393047\n",
      "step :  10\n",
      "d_loss 0.66884196\n",
      "a_loss 0.6951211\n",
      "step :  11\n",
      "d_loss 0.64383936\n",
      "a_loss 0.657067\n",
      "step :  12\n",
      "d_loss 0.7228395\n",
      "a_loss 0.6442342\n",
      "step :  13\n",
      "d_loss 0.7709808\n",
      "a_loss 0.97369576\n",
      "step :  14\n",
      "d_loss 0.6504017\n",
      "a_loss 1.3812304\n",
      "step :  15\n",
      "d_loss 0.7676292\n",
      "a_loss 0.736438\n",
      "step :  16\n",
      "d_loss 0.7156118\n",
      "a_loss 0.6888987\n",
      "step :  17\n",
      "d_loss 0.6492737\n",
      "a_loss 0.6461959\n",
      "step :  18\n",
      "d_loss 0.6949375\n",
      "a_loss 0.6278658\n",
      "step :  19\n",
      "d_loss 0.7605341\n",
      "a_loss 0.9093114\n",
      "step :  20\n",
      "d_loss 0.6746925\n",
      "a_loss 0.76617944\n",
      "step :  21\n",
      "d_loss 0.6987909\n",
      "a_loss 0.6762173\n",
      "step :  22\n",
      "d_loss 0.6731154\n",
      "a_loss 0.63643354\n",
      "step :  23\n",
      "d_loss 0.67771333\n",
      "a_loss 0.73750967\n",
      "step :  24\n",
      "d_loss 0.6571304\n",
      "a_loss 0.7230986\n",
      "step :  25\n",
      "d_loss 0.67143667\n",
      "a_loss 0.598451\n",
      "step :  26\n",
      "d_loss 0.8993986\n",
      "a_loss 1.2081509\n",
      "step :  27\n",
      "d_loss 0.7462153\n",
      "a_loss 0.6935049\n",
      "step :  28\n",
      "d_loss 0.6890586\n",
      "a_loss 0.634048\n",
      "step :  29\n",
      "d_loss 0.625778\n",
      "a_loss 0.5514165\n",
      "step :  30\n",
      "d_loss 0.9022066\n",
      "a_loss 0.90633947\n",
      "step :  31\n",
      "d_loss 0.7412852\n",
      "a_loss 0.6326773\n",
      "step :  32\n",
      "d_loss 0.69639325\n",
      "a_loss 0.6135391\n",
      "step :  33\n",
      "d_loss 0.73896444\n",
      "a_loss 0.63001764\n",
      "step :  34\n",
      "d_loss 0.7537509\n",
      "a_loss 0.9044801\n",
      "step :  35\n",
      "d_loss 0.739783\n",
      "a_loss 0.6936668\n",
      "step :  36\n",
      "d_loss 0.70184886\n",
      "a_loss 0.65163505\n",
      "step :  37\n",
      "d_loss 0.687155\n",
      "a_loss 0.6145441\n",
      "step :  38\n",
      "d_loss 0.7537405\n",
      "a_loss 0.7375641\n",
      "step :  39\n",
      "d_loss 0.6884645\n",
      "a_loss 0.6767882\n",
      "step :  40\n",
      "d_loss 0.72412616\n",
      "a_loss 0.7727045\n",
      "step :  41\n",
      "d_loss 0.68190587\n",
      "a_loss 0.64079636\n",
      "step :  42\n",
      "d_loss 0.73094356\n",
      "a_loss 0.8303789\n",
      "step :  43\n",
      "d_loss 0.74668664\n",
      "a_loss 0.6265111\n",
      "step :  44\n",
      "d_loss 0.6866361\n",
      "a_loss 0.76016617\n",
      "step :  45\n",
      "d_loss 0.7140899\n",
      "a_loss 0.61634594\n",
      "step :  46\n",
      "d_loss 0.7002567\n",
      "a_loss 0.750871\n",
      "step :  47\n",
      "d_loss 0.7209116\n",
      "a_loss 0.65410674\n",
      "step :  48\n",
      "d_loss 0.68836194\n",
      "a_loss 0.70347095\n",
      "step :  49\n",
      "d_loss 0.67480516\n",
      "a_loss 0.5742339\n",
      "step :  50\n",
      "d_loss 0.83132017\n",
      "a_loss 1.8979585\n",
      "step :  51\n",
      "d_loss 1.1105812\n",
      "a_loss 0.6381855\n",
      "step :  52\n",
      "d_loss 0.6443928\n",
      "a_loss 0.5103258\n",
      "step :  53\n",
      "d_loss 0.96626747\n",
      "a_loss 1.0852622\n",
      "step :  54\n",
      "d_loss 0.77245826\n",
      "a_loss 0.6559111\n",
      "step :  55\n",
      "d_loss 0.59147877\n",
      "a_loss 0.53398687\n",
      "step :  56\n",
      "d_loss 0.73206896\n",
      "a_loss 0.6835743\n",
      "step :  57\n",
      "d_loss 0.6430934\n",
      "a_loss 0.65150696\n",
      "step :  58\n",
      "d_loss 0.73280054\n",
      "a_loss 0.58570296\n",
      "step :  59\n",
      "d_loss 0.8560909\n",
      "a_loss 2.8769844\n",
      "step :  60\n",
      "d_loss 1.1119173\n",
      "a_loss 0.70508957\n",
      "step :  61\n",
      "d_loss 0.68124145\n",
      "a_loss 0.5701017\n",
      "step :  62\n",
      "d_loss 0.61658657\n",
      "a_loss 0.52186877\n",
      "step :  63\n",
      "d_loss 0.66538996\n",
      "a_loss 0.58459187\n",
      "step :  64\n",
      "d_loss 0.7919194\n",
      "a_loss 0.92783165\n",
      "step :  65\n",
      "d_loss 0.8520109\n",
      "a_loss 0.5435749\n",
      "step :  66\n",
      "d_loss 0.79787004\n",
      "a_loss 0.7915114\n",
      "step :  67\n",
      "d_loss 0.7465045\n",
      "a_loss 0.5099999\n",
      "step :  68\n",
      "d_loss 0.8909545\n",
      "a_loss 1.030403\n",
      "step :  69\n",
      "d_loss 0.80366725\n",
      "a_loss 0.6316582\n",
      "step :  70\n",
      "d_loss 0.6672586\n",
      "a_loss 0.5455081\n",
      "step :  71\n",
      "d_loss 0.7550535\n",
      "a_loss 0.82329863\n",
      "step :  72\n",
      "d_loss 0.7468254\n",
      "a_loss 0.4503193\n",
      "step :  73\n",
      "d_loss 0.9886979\n",
      "a_loss 1.6683733\n",
      "step :  74\n",
      "d_loss 0.94689596\n",
      "a_loss 0.61595285\n",
      "step :  75\n",
      "d_loss 0.6348461\n",
      "a_loss 0.5004601\n",
      "step :  76\n",
      "d_loss 0.84272736\n",
      "a_loss 1.0489835\n",
      "step :  77\n",
      "d_loss 0.84900796\n",
      "a_loss 0.5354549\n",
      "step :  78\n",
      "d_loss 0.66254\n",
      "a_loss 0.5094687\n",
      "step :  79\n",
      "d_loss 0.8573011\n",
      "a_loss 0.53108644\n",
      "step :  80\n",
      "d_loss 0.7499684\n",
      "a_loss 0.79907537\n",
      "step :  81\n",
      "d_loss 0.8182583\n",
      "a_loss 0.4862093\n",
      "step :  82\n",
      "d_loss 0.8782445\n",
      "a_loss 1.031656\n",
      "step :  83\n",
      "d_loss 0.8235046\n",
      "a_loss 0.526959\n",
      "step :  84\n",
      "d_loss 0.74510115\n",
      "a_loss 0.59632987\n",
      "step :  85\n",
      "d_loss 0.7130871\n",
      "a_loss 0.50449955\n",
      "step :  86\n",
      "d_loss 0.81333905\n",
      "a_loss 1.2754014\n",
      "step :  87\n",
      "d_loss 0.8466259\n",
      "a_loss 0.4735609\n",
      "step :  88\n",
      "d_loss 0.7615887\n",
      "a_loss 0.833907\n",
      "step :  89\n",
      "d_loss 0.7168789\n",
      "a_loss 0.48828846\n",
      "step :  90\n",
      "d_loss 0.9120134\n",
      "a_loss 1.1555045\n",
      "step :  91\n",
      "d_loss 0.82392234\n",
      "a_loss 0.4920419\n",
      "step :  92\n",
      "d_loss 0.7685941\n",
      "a_loss 0.7420019\n",
      "step :  93\n",
      "d_loss 0.6497803\n",
      "a_loss 0.5334343\n",
      "step :  94\n",
      "d_loss 0.75776637\n",
      "a_loss 0.80692756\n",
      "step :  95\n",
      "d_loss 0.7977375\n",
      "a_loss 0.40273166\n",
      "step :  96\n",
      "d_loss 1.0292212\n",
      "a_loss 1.6980499\n",
      "step :  97\n",
      "d_loss 1.2877249\n",
      "a_loss 0.42778143\n",
      "step :  98\n",
      "d_loss 1.151725\n",
      "a_loss 1.8498758\n",
      "step :  99\n",
      "d_loss 1.3265707\n",
      "a_loss 0.5010537\n",
      "step :  100\n",
      "d_loss 0.7232534\n",
      "a_loss 0.5168046\n",
      "step :  101\n",
      "d_loss 0.67372954\n",
      "a_loss 0.6178287\n",
      "step :  102\n",
      "d_loss 0.97723544\n",
      "a_loss 0.38024396\n",
      "step :  103\n",
      "d_loss 1.1461182\n",
      "a_loss 2.7966623\n",
      "step :  104\n",
      "d_loss 1.3636984\n",
      "a_loss 0.50285804\n",
      "step :  105\n",
      "d_loss 0.7955321\n",
      "a_loss 0.51341826\n",
      "step :  106\n",
      "d_loss 0.89954245\n",
      "a_loss 0.93707645\n",
      "step :  107\n",
      "d_loss 1.0665314\n",
      "a_loss 0.36127892\n",
      "step :  108\n",
      "d_loss 1.1064695\n",
      "a_loss 1.0001693\n",
      "step :  109\n",
      "d_loss 0.6816827\n",
      "a_loss 0.6141982\n",
      "step :  110\n",
      "d_loss 0.7149582\n",
      "a_loss 0.36593527\n",
      "step :  111\n",
      "d_loss 0.95285237\n",
      "a_loss 0.7295025\n",
      "step :  112\n",
      "d_loss 0.83486766\n",
      "a_loss 0.5260156\n",
      "step :  113\n",
      "d_loss 0.8181651\n",
      "a_loss 0.66183627\n",
      "step :  114\n",
      "d_loss 0.7927904\n",
      "a_loss 0.3552107\n",
      "step :  115\n",
      "d_loss 1.2791309\n",
      "a_loss 3.6863186\n",
      "step :  116\n",
      "d_loss 2.2805073\n",
      "a_loss 0.41970366\n",
      "step :  117\n",
      "d_loss 0.8759794\n",
      "a_loss 0.4080046\n",
      "step :  118\n",
      "d_loss 0.80881244\n",
      "a_loss 0.80736005\n",
      "step :  119\n",
      "d_loss 0.97347385\n",
      "a_loss 0.37149936\n",
      "step :  120\n",
      "d_loss 1.0763185\n",
      "a_loss 1.247429\n",
      "step :  121\n",
      "d_loss 0.9201816\n",
      "a_loss 0.41219702\n",
      "step :  122\n",
      "d_loss 0.79602736\n",
      "a_loss 0.7323413\n",
      "step :  123\n",
      "d_loss 0.81804055\n",
      "a_loss 0.2546736\n",
      "step :  124\n",
      "d_loss 1.2630527\n",
      "a_loss 1.3232257\n",
      "step :  125\n",
      "d_loss 1.3903654\n",
      "a_loss 0.24218602\n",
      "step :  126\n",
      "d_loss 1.1421108\n",
      "a_loss 0.42867613\n",
      "step :  127\n",
      "d_loss 0.8289688\n",
      "a_loss 0.63097864\n",
      "step :  128\n",
      "d_loss 0.6807679\n",
      "a_loss 0.6511955\n",
      "step :  129\n",
      "d_loss 0.7243173\n",
      "a_loss 0.5913436\n",
      "step :  130\n",
      "d_loss 1.1258659\n",
      "a_loss 0.3804409\n",
      "step :  131\n",
      "d_loss 1.1416857\n",
      "a_loss 1.8995327\n",
      "step :  132\n",
      "d_loss 1.9182777\n",
      "a_loss 0.21211112\n",
      "step :  133\n",
      "d_loss 1.2867914\n",
      "a_loss 0.46422625\n",
      "step :  134\n",
      "d_loss 0.95565975\n",
      "a_loss 0.77230674\n",
      "step :  135\n",
      "d_loss 0.755792\n",
      "a_loss 0.39181978\n",
      "step :  136\n",
      "d_loss 1.0407674\n",
      "a_loss 1.0727981\n",
      "step :  137\n",
      "d_loss 1.4071871\n",
      "a_loss 0.124426045\n",
      "step :  138\n",
      "d_loss 1.6893775\n",
      "a_loss 0.3046123\n",
      "step :  139\n",
      "d_loss 1.1478916\n",
      "a_loss 1.2305634\n",
      "step :  140\n",
      "d_loss 1.3739865\n",
      "a_loss 0.18784064\n",
      "step :  141\n",
      "d_loss 1.5162233\n",
      "a_loss 0.32155293\n",
      "step :  142\n",
      "d_loss 0.9470097\n",
      "a_loss 0.9528681\n",
      "step :  143\n",
      "d_loss 1.4889057\n",
      "a_loss 0.08669927\n",
      "step :  144\n",
      "d_loss 2.1161265\n",
      "a_loss 0.5893563\n",
      "step :  145\n",
      "d_loss 1.3438828\n",
      "a_loss 0.042551197\n",
      "step :  146\n",
      "d_loss 3.352864\n",
      "a_loss 2.5477507\n",
      "step :  147\n",
      "d_loss 2.2051344\n",
      "a_loss 0.23072526\n",
      "step :  148\n",
      "d_loss 1.7244136\n",
      "a_loss 0.2975287\n",
      "step :  149\n",
      "d_loss 1.9878061\n",
      "a_loss 2.4501386\n",
      "step :  150\n",
      "d_loss 3.034041\n",
      "a_loss 0.27601045\n",
      "step :  151\n",
      "d_loss 1.2169269\n",
      "a_loss 0.25810736\n",
      "step :  152\n",
      "d_loss 1.1582687\n",
      "a_loss 0.5320412\n",
      "step :  153\n",
      "d_loss 0.967182\n",
      "a_loss 0.4793211\n",
      "step :  154\n",
      "d_loss 1.085195\n",
      "a_loss 0.11069977\n",
      "step :  155\n",
      "d_loss 1.805574\n",
      "a_loss 1.5413897\n",
      "step :  156\n",
      "d_loss 1.9079326\n",
      "a_loss 0.16459927\n",
      "step :  157\n",
      "d_loss 1.656916\n",
      "a_loss 0.23686738\n",
      "step :  158\n",
      "d_loss 1.2139655\n",
      "a_loss 0.5747756\n",
      "step :  159\n",
      "d_loss 1.3203553\n",
      "a_loss 0.18805638\n",
      "step :  160\n",
      "d_loss 1.7830807\n",
      "a_loss 0.97362614\n",
      "step :  161\n",
      "d_loss 1.3635466\n",
      "a_loss 0.0788133\n",
      "step :  162\n",
      "d_loss 1.8208557\n",
      "a_loss 0.5634823\n",
      "step :  163\n",
      "d_loss 1.0930228\n",
      "a_loss 0.5556162\n",
      "step :  164\n",
      "d_loss 1.2012683\n",
      "a_loss 0.5746026\n",
      "step :  165\n",
      "d_loss 1.1705827\n",
      "a_loss 0.22802976\n",
      "step :  166\n",
      "d_loss 1.6421051\n",
      "a_loss 4.1141644\n",
      "step :  167\n",
      "d_loss 4.1709185\n",
      "a_loss 0.17735529\n",
      "step :  168\n",
      "d_loss 1.5285794\n",
      "a_loss 0.20734477\n",
      "step :  169\n",
      "d_loss 1.6062412\n",
      "a_loss 0.8749552\n",
      "step :  170\n",
      "d_loss 1.4720978\n",
      "a_loss 0.0662175\n",
      "step :  171\n",
      "d_loss 1.9323088\n",
      "a_loss 0.2390475\n",
      "step :  172\n",
      "d_loss 1.5841621\n",
      "a_loss 1.234433\n",
      "step :  173\n",
      "d_loss 1.3266885\n",
      "a_loss 0.20335181\n",
      "step :  174\n",
      "d_loss 1.3523953\n",
      "a_loss 0.26814407\n",
      "step :  175\n",
      "d_loss 1.0563759\n",
      "a_loss 0.65710795\n",
      "step :  176\n",
      "d_loss 0.8779314\n",
      "a_loss 0.47006464\n",
      "step :  177\n",
      "d_loss 0.90065783\n",
      "a_loss 0.47676188\n",
      "step :  178\n",
      "d_loss 0.8735687\n",
      "a_loss 0.3096668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step :  179\n",
      "d_loss 1.330062\n",
      "a_loss 1.5066023\n",
      "step :  180\n",
      "d_loss 1.6709007\n",
      "a_loss 0.0910425\n",
      "step :  181\n",
      "d_loss 1.8235295\n",
      "a_loss 0.24747822\n",
      "step :  182\n",
      "d_loss 1.1330538\n",
      "a_loss 0.7855701\n",
      "step :  183\n",
      "d_loss 1.1382055\n",
      "a_loss 0.045762062\n",
      "step :  184\n",
      "d_loss 2.2863827\n",
      "a_loss 0.45409274\n",
      "step :  185\n",
      "d_loss 1.5114813\n",
      "a_loss 0.12609346\n",
      "step :  186\n",
      "d_loss 2.250484\n",
      "a_loss 4.0958395\n",
      "step :  187\n",
      "d_loss 5.2505307\n",
      "a_loss 0.13764007\n",
      "step :  188\n",
      "d_loss 2.3108432\n",
      "a_loss 0.17404574\n",
      "step :  189\n",
      "d_loss 1.7047154\n",
      "a_loss 2.7697742\n",
      "step :  190\n",
      "d_loss 4.1864977\n",
      "a_loss 0.16017486\n",
      "step :  191\n",
      "d_loss 1.3759648\n",
      "a_loss 0.20644799\n",
      "step :  192\n",
      "d_loss 1.4145163\n",
      "a_loss 0.31277746\n",
      "step :  193\n",
      "d_loss 1.3927205\n",
      "a_loss 0.260949\n",
      "step :  194\n",
      "d_loss 1.6664807\n",
      "a_loss 0.86240256\n",
      "step :  195\n",
      "d_loss 1.6986492\n",
      "a_loss 0.13060899\n",
      "step :  196\n",
      "d_loss 1.6860063\n",
      "a_loss 0.26846984\n",
      "step :  197\n",
      "d_loss 1.3478934\n",
      "a_loss 1.4319645\n",
      "step :  198\n",
      "d_loss 3.9238155\n",
      "a_loss 0.048028313\n",
      "step :  199\n",
      "d_loss 2.2828414\n",
      "a_loss 0.13607141\n",
      "step :  200\n",
      "d_loss 1.7478584\n",
      "a_loss 0.24590032\n",
      "step :  201\n",
      "d_loss 1.626339\n",
      "a_loss 0.5348364\n",
      "step :  202\n",
      "d_loss 1.6800396\n",
      "a_loss 0.15401119\n",
      "step :  203\n",
      "d_loss 2.33362\n",
      "a_loss 1.1967065\n",
      "step :  204\n",
      "d_loss 1.2534504\n",
      "a_loss 0.11803901\n",
      "step :  205\n",
      "d_loss 1.8837208\n",
      "a_loss 0.20909365\n",
      "step :  206\n",
      "d_loss 1.3678643\n",
      "a_loss 0.7185497\n",
      "step :  207\n",
      "d_loss 2.0922377\n",
      "a_loss 0.06071045\n",
      "step :  208\n",
      "d_loss 2.463473\n",
      "a_loss 0.35125425\n",
      "step :  209\n",
      "d_loss 1.481901\n",
      "a_loss 0.92258537\n",
      "step :  210\n",
      "d_loss 1.9329838\n",
      "a_loss 0.06572808\n",
      "step :  211\n",
      "d_loss 2.8986435\n",
      "a_loss 0.3206161\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-93-fe190c0c02fb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mmisleading_targets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0ma_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_latent_vectors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmisleading_targets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"step : \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1217\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1218\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start = 0 \n",
    "for step in range(iterations):\n",
    "    random_latent_vectors = np.random.normal(size=(batch_size,latent_dim))\n",
    "    generated_images = generator.predict(random_latent_vectors)\n",
    "    stop = start + batch_size\n",
    "    real_images = x_train[start : stop]\n",
    "    combined_images = np.concatenate([generated_images, real_images])\n",
    "    labels = np.concatenate([np.ones((batch_size,1)),\\\n",
    "                            np.zeros((batch_size,1))])\n",
    "    labels += 0.05 * np.random.random(labels.shape)\n",
    "    d_loss = discriminator.train_on_batch(combined_images, labels)\n",
    "    \n",
    "    random_latent_vectors = np.random.normal(size = (batch_size, latent_dim))\n",
    "    \n",
    "    misleading_targets = np.zeros((batch_size,1))\n",
    "    \n",
    "    a_loss = gan.train_on_batch(random_latent_vectors, misleading_targets)\n",
    "    \n",
    "    print(\"step : \", step)\n",
    "    print(\"d_loss\",d_loss)\n",
    "    print(\"a_loss\",a_loss)\n",
    "    start += batch_size \n",
    "    if start > len(x_train) - batch_size : \n",
    "        start =0\n",
    "    if step % 10 == 0 :\n",
    "        gan.save_weights(\"gan.h5\")\n",
    "        img = image.array_to_img(generated_images[0] * 255., scale=False)\n",
    "        img.save(os.path.join(save_dir,'generated_frog'+str(step)+\".png\"))\n",
    "        \n",
    "        img = image.array_to_img(real_images[0]*255.,scale=False)\n",
    "        img.save(os.path.join(save_dir,'real_frog'+str(step)+\".png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSGAN():\n",
    "    def __init__(self):\n",
    "        self.latent_dim = 32\n",
    "        self.img_channel_num = 128 #generator 에서 생성될 channel num\n",
    "        self.img_row_shape = 16 #generator 에서 생성될 row\n",
    "        self.img_col_shape = 16 #generator 에서 생성될 col\n",
    "        self.output_channels = 3 #generator 에서 나올 channels 당연히 3\n",
    "        \n",
    "        self.row = 32 #discriminator에 들어갈 row shape = generator의 output\n",
    "        self.col = 32 #discriminator에 들어갈 col shape\n",
    "        self.generator = self.build_generator()\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator_optimizer = Adam(lr=0.0002)\n",
    "        self.gan_optimizer = Adam(lr =0.0002)\n",
    "        self.discriminator.compile(loss = 'mse', optimizer = self.discriminator_optimizer,\\\n",
    "                                  metrics = ['accuracy'])\n",
    "        \n",
    "        self.discriminator.trainable = False\n",
    "        \n",
    "        self.gan = self.discriminator(self.generator)\n",
    "        self.gan.compile(loss = 'mse',optimizer = self.gan_optimizer)\n",
    "        \n",
    "    def build_generator(self):\n",
    "        generator_input = Input(shape=(self.latent_dim,))\n",
    "        x = Dense(self.img_channel_num * self.img_row_shape * self.img_col_shape)(generator_input)\n",
    "        x = LeakyReLU()(x)            \n",
    "        x = Reshape((self.img_row_shape,self.img_col_shape,self.img_channel_num))(x)\n",
    "\n",
    "        x = Conv2D(256,5, padding= 'same')(x)\n",
    "        x = LeakyReLU()(x)\n",
    "\n",
    "        x = Conv2DTranspose(256,4, strides = 2, padding='same')(x)\n",
    "        x = LeakyReLU()(x)\n",
    "\n",
    "        x = Conv2D(256, 5, padding = 'same')(x)\n",
    "        x = LeakyReLU()(x)\n",
    "        x = Conv2D(256, 5, padding = 'same')(x)\n",
    "        x = LeakyReLU()(x)\n",
    "        x = Conv2D(self.output_channels, 7 , activation = 'tanh',padding = 'same')(x)\n",
    "        generator = Model(generator_input,x)\n",
    "        return generator\n",
    "    \n",
    "    def build_discriminator(self):\n",
    "        discriminator_input = Input(shape = (self.row,self.col,self.output_channels))\n",
    "        x = Conv2D(128,3)(discriminator_input)\n",
    "        x = LeakyReLU()(x)\n",
    "\n",
    "        x = Conv2D(128,4, strides = 2)(x)\n",
    "        x = LeakyReLU()(x)\n",
    "        x = Conv2D(128,4, strides = 2)(x)\n",
    "        x = LeakyReLU()(x)\n",
    "        x = Conv2D(128,4, strides = 2)(x)\n",
    "        x = LeakyReLU()(x)\n",
    "        x = Flatten()(x)\n",
    "\n",
    "        x = Dropout(0.4)(x)\n",
    "        x = Dense(1,activation = 'sigmoid')(x)\n",
    "        discriminator = Model(discriminator_input,x)\n",
    "        return discriminator\n",
    "        \n",
    "    def train(self, X_train,epochs, batch_size=128, sample_interval=50):\n",
    "\n",
    "        # Rescale -1 to 1\n",
    "        X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Discriminator\n",
    "            # ---------------------\n",
    "\n",
    "            # Select a random batch of images\n",
    "            idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "            imgs = X_train[idx]\n",
    "\n",
    "            # Sample noise as generator input\n",
    "            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "\n",
    "            # Generate a batch of new images\n",
    "            gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "            # Train the discriminator\n",
    "            d_loss_real = self.discriminator.train_on_batch(imgs, valid)\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Generator\n",
    "            # ---------------------\n",
    "\n",
    "            g_loss = self.gan.train_on_batch(noise, valid)\n",
    "\n",
    "            # Plot the progress\n",
    "            print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
    "\n",
    "            # If at save interval => save generated image samples\n",
    "            if epoch % sample_interval == 0:\n",
    "                self.sample_images(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Layer model_26 was called with an input that isn't a symbolic tensor. Received type: <class 'keras.engine.training.Model'>. Full input: [<keras.engine.training.Model object at 0x0000022C36A9F438>]. All inputs to the layer should be tensors.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    278\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 279\u001b[1;33m                 \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_keras_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    280\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mis_keras_tensor\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    473\u001b[0m         raise ValueError('Unexpectedly found an instance of type `' +\n\u001b[1;32m--> 474\u001b[1;33m                          \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'`. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    475\u001b[0m                          'Expected a symbolic tensor instance.')\n",
      "\u001b[1;31mValueError\u001b[0m: Unexpectedly found an instance of type `<class 'keras.engine.training.Model'>`. Expected a symbolic tensor instance.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-99-921a9e0f386b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLSGAN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-96-337df8b28e8d>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgan\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'mse'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgan_optimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[0;32m    438\u001b[0m             \u001b[1;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m             \u001b[1;31m# with the input_spec set at build time.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m             \u001b[1;31m# Handle mask propagation.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    283\u001b[0m                                  \u001b[1;34m'Received type: '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m                                  \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'. Full input: '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 285\u001b[1;33m                                  \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'. All inputs to the layer '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    286\u001b[0m                                  'should be tensors.')\n\u001b[0;32m    287\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Layer model_26 was called with an input that isn't a symbolic tensor. Received type: <class 'keras.engine.training.Model'>. Full input: [<keras.engine.training.Model object at 0x0000022C36A9F438>]. All inputs to the layer should be tensors."
     ]
    }
   ],
   "source": [
    "model = LSGAN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
